{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 18422222637 sequences.\n",
      "\n",
      "Batch 1\n",
      "Inputs shape: torch.Size([1, 100])\n",
      "Sequence: ked to stay indoors and piece bedquilts and knit stockings and read aloud to my mother i never willi\n",
      "\n",
      "Batch 2\n",
      "Inputs shape: torch.Size([1, 100])\n",
      "Sequence: lle eyes were two dancing stars she clapped her hands in riotous glee without a word she untied the \n"
     ]
    }
   ],
   "source": [
    "from dataset_creation import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Instantiate the dataset\n",
    "text_dataset = TextDataset(directory='data/SPGC-tokens-2018-07-18/', sequence_length=100)\n",
    "print(f\"Dataset created with {len(text_dataset)} sequences.\")\n",
    "\n",
    "# Create a DataLoader without a sampler\n",
    "dataloader = DataLoader(text_dataset, batch_size=1)\n",
    "\n",
    "# Iterate over a few batches and print their contents\n",
    "for i, (sequences, inputs) in enumerate(dataloader):\n",
    "    if i >= 2:  # Adjust this value to see more/less batches\n",
    "        break\n",
    "\n",
    "    print(f\"\\nBatch {i+1}\")\n",
    "    print(f\"Inputs shape: {inputs.shape}\")\n",
    "\n",
    "    # Optionally print the actual sequences (comment out if too verbose)\n",
    "    sequence = ''.join([text_dataset.idx_to_char[int(idx)] for idx in inputs[0]])\n",
    "    # target = text_dataset.idx_to_char[int(targets[0])]\n",
    "    print(f\"Sequence: {sequence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 70\n",
      "Characters: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', '.', ';', \"'\", '\"', '?', '!', ' ']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define chars using keys of char_to_idx\n",
    "chars = list(text_dataset.char_to_idx.keys())\n",
    "\n",
    "n_characters = len(chars)  # Number of unique characters\n",
    "print(f\"Number of unique characters: {n_characters}\")\n",
    "print(f\"Characters: {chars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weights: torch.Size([5, 10])\n",
      "Shape of imprints: torch.Size([5, 10])\n",
      "Are the shapes identical? True\n",
      "Weights:\n",
      "  Parameter containing:\n",
      "tensor([[ 0.2057,  0.0184, -0.0532, -0.2423, -0.1152,  0.2199,  0.0706,  0.1025,\n",
      "          0.2512,  0.1289],\n",
      "        [-0.1553,  0.1646, -0.2277,  0.0446, -0.2705, -0.0454, -0.0052,  0.1286,\n",
      "          0.0754, -0.1740],\n",
      "        [-0.1229, -0.2632, -0.1724,  0.2134, -0.2646,  0.1718, -0.1688, -0.2379,\n",
      "          0.0897,  0.2443],\n",
      "        [ 0.1675,  0.0302, -0.0020,  0.2903,  0.3014,  0.3121,  0.0762, -0.2685,\n",
      "         -0.3103, -0.1092],\n",
      "        [ 0.0512, -0.2552,  0.0375,  0.0566,  0.1504,  0.1837,  0.2226, -0.0789,\n",
      "         -0.2185, -0.1551]], requires_grad=True)\n",
      "Weights after imprint:\n",
      "  Parameter containing:\n",
      "tensor([[ 0.2327,  0.0167, -0.0805, -0.2949, -0.2308,  0.2357,  0.0302,  0.1919,\n",
      "          0.3288,  0.1569],\n",
      "        [-0.2179,  0.1636, -0.1931,  0.0697, -0.3843, -0.0942,  0.0114,  0.3153,\n",
      "          0.1237, -0.1191],\n",
      "        [-0.0410, -0.2689, -0.2244,  0.1348, -0.2900,  0.2352, -0.2366, -0.3050,\n",
      "          0.1323,  0.2165],\n",
      "        [ 0.2107,  0.0357, -0.0176,  0.3148,  0.5406,  0.3478,  0.1038, -0.5615,\n",
      "         -0.4405, -0.1911],\n",
      "        [ 0.0194, -0.2538,  0.0685,  0.1137,  0.2673,  0.1647,  0.2659, -0.1645,\n",
      "         -0.2984, -0.1826]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HebbianLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(HebbianLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.imprints = nn.Parameter(torch.zeros_like(self.weight))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # print(input)\n",
    "        output = super(HebbianLinear, self).forward(input)\n",
    "        self.update_imprints(input, output)\n",
    "        # print(output)\n",
    "        return output\n",
    "\n",
    "    def update_imprints(self, input, output):\n",
    "        # print(\"input shape:\", input.shape)\n",
    "        # print(\"output shape:\", output.shape)\n",
    "    \n",
    "        # Hebbian update rule: imprint = input * output\n",
    "        # Adjusting to compute the required [5, 10] imprint matrix for each batch\n",
    "        # Reshape input and output for broadcasting\n",
    "        input_expanded = input.unsqueeze(1)  # Shape: [batch_size, 1, in_features]\n",
    "        output_expanded = output.unsqueeze(2)  # Shape: [batch_size, out_features, 1]\n",
    "\n",
    "        # Element-wise multiplication with broadcasting\n",
    "        # Results in a [batch_size, out_features, in_features] tensor\n",
    "        imprint_update = output_expanded * input_expanded\n",
    "\n",
    "        # Sum over the batch dimension to get the final imprint update\n",
    "        self.imprints.data = imprint_update.sum(dim=0)\n",
    "\n",
    "\n",
    "\n",
    "    def apply_imprints(self, reward, learning_rate):\n",
    "        # Apply the imprints to the weights\n",
    "        # self.weight.data += reward * learning_rate * self.imprints\n",
    "        imprint_update = self.imprints.data\n",
    "        # print(\"norm_imprint_update:\", norm_imprint_update)\n",
    "\n",
    "        # Apply the normalized imprints\n",
    "        # The reward can be positive (for LTP) or negative (for LTD)\n",
    "        self.weight.data += reward * learning_rate * imprint_update\n",
    "\n",
    "\n",
    "# Example instantiation of HebbianLinear\n",
    "layer = HebbianLinear(in_features=10, out_features=5)\n",
    "\n",
    "# Checking if the shapes are the same\n",
    "print(\"Shape of weights:\", layer.weight.shape)\n",
    "print(\"Shape of imprints:\", layer.imprints.shape)\n",
    "print(\"Are the shapes identical?\", layer.weight.shape == layer.imprints.shape)\n",
    "\n",
    "# Generate random data\n",
    "input_data = torch.randn(3, 10)  # Batch size of 3, input features 10\n",
    "\n",
    "# Pass data through the HebbianLinear layer\n",
    "output = layer(input_data)\n",
    "\n",
    "print(\"Weights:\\n \", layer.weight)\n",
    "layer.apply_imprints(reward=0.5, learning_rate=0.1)\n",
    "print(\"Weights after imprint:\\n \", layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Using HebbianLinear instead of Linear\n",
    "        self.linear_layers = torch.nn.ModuleList([HebbianLinear(input_size + hidden_size, hidden_size)])\n",
    "        for _ in range(1, num_layers):\n",
    "            self.linear_layers.append(HebbianLinear(hidden_size, hidden_size))\n",
    "\n",
    "        # Final layers for hidden and output, also using HebbianLinear\n",
    "        self.i2h = HebbianLinear(hidden_size, hidden_size)\n",
    "        self.i2o = HebbianLinear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "\n",
    "        # Pass through the Hebbian linear layers with ReLU\n",
    "        for layer in self.linear_layers:\n",
    "            combined = layer(combined)\n",
    "            combined = F.relu(combined)\n",
    "\n",
    "        # Split into hidden and output\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        # print(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "    def apply_imprints(self, reward, learning_rate):\n",
    "        # Apply imprints for all HebbianLinear layers\n",
    "        for layer in self.linear_layers:\n",
    "            layer.apply_imprints(reward, learning_rate)\n",
    "        self.i2h.apply_imprints(reward, learning_rate)\n",
    "        self.i2o.apply_imprints(reward, learning_rate)\n",
    "\n",
    "\n",
    "# Ensure the input size matches the number of features for each input\n",
    "input_size = n_characters\n",
    "output_size = n_characters\n",
    "n_hidden = 128\n",
    "rnn = SimpleRNN(input_size, n_hidden, output_size,3)\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = torch.nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "\n",
    "# Apply Clipping\n",
    "def clip_weights(model, max_norm):\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param.data.clamp_(-max_norm, max_norm)\n",
    "\n",
    "# In your training loop, after the weight update step\n",
    "clip_weights(rnn, max_norm=0.5)  # Choose an appropriate max_norm value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([5, 1, 70])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return text_dataset.char_to_idx[letter]\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_characters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_characters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_characters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_characters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('em entering into my humor she improvised a cockpit by spreading her upon the ground and i liberated ',\n",
       " tensor([ 4, 12, 69,  4, 13, 19,  4, 17,  8, 13,  6, 69,  8, 13, 19, 14, 69, 12,\n",
       "         24, 69,  7, 20, 12, 14, 17, 69, 18,  7,  4, 69,  8, 12, 15, 17, 14, 21,\n",
       "          8, 18,  4,  3, 69,  0, 69,  2, 14,  2, 10, 15,  8, 19, 69,  1, 24, 69,\n",
       "         18, 15, 17,  4,  0,  3,  8, 13,  6, 69,  7,  4, 17, 69, 20, 15, 14, 13,\n",
       "         69, 19,  7,  4, 69,  6, 17, 14, 20, 13,  3, 69,  0, 13,  3, 69,  8, 69,\n",
       "         11,  8,  1,  4, 17,  0, 19,  4,  3, 69]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wn i will to rome go thou and with thy train pursue mithridates till he be slain lucullus with fortu',\n",
       " tensor([22, 13, 69,  8, 69, 22,  8, 11, 11, 69, 19, 14, 69, 17, 14, 12,  4, 69,\n",
       "          6, 14, 69, 19,  7, 14, 20, 69,  0, 13,  3, 69, 22,  8, 19,  7, 69, 19,\n",
       "          7, 24, 69, 19, 17,  0,  8, 13, 69, 15, 20, 17, 18, 20,  4, 69, 12,  8,\n",
       "         19,  7, 17,  8,  3,  0, 19,  4, 18, 69, 19,  8, 11, 11, 69,  7,  4, 69,\n",
       "          1,  4, 69, 18, 11,  0,  8, 13, 69, 11, 20,  2, 20, 11, 11, 20, 18, 69,\n",
       "         22,  8, 19,  7, 69,  5, 14, 17, 19, 20]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomTrainingExample():\n",
    "    \"\"\"Generate a random training example from the dataset\"\"\"\n",
    "    sequence, line_tensor = text_dataset[np.random.randint(len(text_dataset))]\n",
    "    return sequence, line_tensor\n",
    "\n",
    "randomTrainingExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "last_n_rewards = [0]\n",
    "last_n_reward_avg = 0\n",
    "n_rewards = 100\n",
    "def train(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0] - 1):\n",
    "        hot_input_char_tensor = torch.nn.functional.one_hot(line_tensor[i], num_classes=n_characters).type(torch.float).unsqueeze(0)\n",
    "        output, hidden = rnn(hot_input_char_tensor, hidden)\n",
    "\n",
    "    # print(\"output shape:\", output.shape)\n",
    "    # print(\"line_tensor shape:\", line_tensor.shape)\n",
    "    # print(output)\n",
    "    # print(line_tensor[-1].unsqueeze(0))\n",
    "    loss = criterion(output, line_tensor[-1].unsqueeze(0))\n",
    "    # print(loss)\n",
    "\n",
    "    # Convert loss to a reward signal\n",
    "    reward = 1 / (1 + loss.item())  # Example conversion, assuming loss is non-negative\n",
    "    # print(reward)\n",
    "\n",
    "    # update last_n_rewards\n",
    "    last_n_rewards.append(reward)\n",
    "    if len(last_n_rewards) > n_rewards:\n",
    "        last_n_rewards.pop(0)\n",
    "    last_n_reward_avg = sum(last_n_rewards) / len(last_n_rewards)\n",
    "    reward_update = reward - last_n_reward_avg\n",
    "    # print(reward_update)\n",
    "    clip_weights(rnn, max_norm=0.5)  # Choose an appropriate max_norm value\n",
    "\n",
    "    # Apply Hebbian updates\n",
    "    rnn.apply_imprints(reward_update, learning_rate)\n",
    "\n",
    "    # Perform backward pass and optimizer step if using gradient descent for other parameters\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09627902347366801\n",
      "0.0642453315029716\n",
      "0.046083009601005476\n",
      "0.036550338035416546\n",
      "0.02995886365938452\n",
      "0.028947107304090253\n",
      "0.025325776341128065\n",
      "0.019604064901092427\n",
      "0.016987131277232753\n",
      "0.019068274528918655\n",
      "0.01714989206326009\n",
      "0.016210976796676407\n",
      "0.011914707214763759\n",
      "0.010103861840715184\n",
      "0.013494057699928813\n",
      "0.009044784627591618\n",
      "0.010443414075461094\n",
      "0.01003859940260654\n",
      "0.007475823462962189\n",
      "0.006646326152155185\n",
      "0.0068187698928294516\n",
      "0.006504288753854337\n",
      "0.008502961416139432\n",
      "0.00827645120457024\n",
      "0.005761683308846632\n",
      "0.006197941165837134\n",
      "0.005424402351804886\n",
      "0.006019772539734541\n",
      "0.008987760879618861\n",
      "0.008878555404941646\n",
      "0.0052438322897759015\n",
      "0.005268968060503559\n",
      "0.0059979155736480105\n",
      "0.004507886615770423\n",
      "0.0073535852093905285\n",
      "0.007149525889566993\n",
      "0.0038436214961371507\n",
      "0.0032562955963362783\n",
      "0.003003029399195445\n",
      "0.005416813867095777\n",
      "0.0027906366118663484\n",
      "0.0033477079831411294\n",
      "0.0065659748606855806\n",
      "0.0030989440121326206\n",
      "0.0035457218308979077\n",
      "0.0033995680068113487\n",
      "0.004308767790565271\n",
      "0.0033226833678544065\n",
      "0.005654918761762273\n",
      "0.00596905287175728\n",
      "50 0% (0m 1s) 4.1904 e visitors looked at the spot without speaking there on this very day in the past amidst the hardly  / m ✗ ( )\n",
      "0.003028513193441079\n",
      "0.0017688672019359475\n",
      "0.005539702140905045\n",
      "0.0018059691531348565\n",
      "0.0027475307954715478\n",
      "0.0018115005478155921\n",
      "0.00555358072514564\n",
      "0.002765744172890522\n",
      "0.004927776193187877\n",
      "0.004874379081692387\n",
      "0.0024252434023050995\n",
      "0.0015207271160929403\n",
      "0.0038763505797772824\n",
      "0.005135344604214331\n",
      "0.0011856369631441377\n",
      "0.005082756535689681\n",
      "0.0010315633130993651\n",
      "0.000991057906219367\n",
      "0.006911207596570462\n",
      "0.0011354462930999176\n",
      "0.004884518055146475\n",
      "0.0013685486794676738\n",
      "0.0007782464660470723\n",
      "0.0009425894715571204\n",
      "0.004717983936136677\n",
      "0.0007338495965859282\n",
      "0.0014149373135425025\n",
      "0.0013919442949382466\n",
      "0.0025693625174139645\n",
      "0.00180450088951159\n",
      "0.004491811890447478\n",
      "0.0012346699537363615\n",
      "0.0005083642982001702\n",
      "0.004530815438986618\n",
      "0.0011995653305723608\n",
      "4.4980625319296363e-05\n",
      "0.0004519362295416218\n",
      "0.0007629212627681403\n",
      "0.006376606615391994\n",
      "0.00222934477422132\n",
      "0.004186276685097745\n",
      "0.0029460439353262147\n",
      "0.0013382920203592608\n",
      "0.0038865115550831553\n",
      "0.00027590903730101424\n",
      "0.002221014488648476\n",
      "0.0013053154927873678\n",
      "0.004011652937549598\n",
      "0.0012597103612395633\n",
      "0.0017152628133745296\n",
      "100 0% (0m 3s) 4.2040 llwyn studio stands wide open and past it in the street the wind is whirling bits of straw and paper / m ✗ (r)\n",
      "-0.0006462655493321423\n",
      "-0.0009951988695357517\n",
      "0.0021119163041043443\n",
      "-0.0016960591553337179\n",
      "0.002226415494828299\n",
      "-0.0016699109288939584\n",
      "-0.0007331594717259193\n",
      "0.0008237884714283883\n",
      "0.0006367792748192269\n",
      "-0.0017326931953730862\n",
      "-0.0006056285311119569\n",
      "-0.0009632609696017536\n",
      "0.002352931722279905\n",
      "0.0022711094163118672\n",
      "0.00032073159980613997\n",
      "-0.0009494794904359449\n",
      "-0.0010495554457166656\n",
      "-0.001259976820469827\n",
      "0.001803752891516297\n",
      "-0.001525110280630515\n",
      "0.00023099906592885522\n",
      "0.002245427658028404\n",
      "0.0021751615960713955\n",
      "0.0021685635270656534\n",
      "0.0016711567062635824\n",
      "-0.0008857765954095043\n",
      "0.002106587896669343\n",
      "0.0006325323343784051\n",
      "-0.0015937138183284294\n",
      "-2.976439013230303e-06\n",
      "-0.0008104883876662028\n",
      "-0.0011822241027531766\n",
      "0.0020038584783910462\n",
      "0.00014302004965235926\n",
      "0.0006941404671110263\n",
      "0.002080465283255395\n",
      "-0.0018701424109492382\n",
      "-0.0016459945257282782\n",
      "0.002089030247016843\n",
      "0.0005062889530949299\n",
      "0.0007418494062305936\n",
      "3.5412892322450595e-06\n",
      "-0.0017359904151873218\n",
      "0.002055818806626336\n",
      "0.0017830858357480717\n",
      "0.0017578501674647418\n",
      "0.0015716977223391437\n",
      "0.0023209986169904495\n",
      "0.001955780702944554\n",
      "0.0006415316242527613\n",
      "150 0% (0m 4s) 4.2268 f is laid down which is the habitual position of the rear sight leaf at drill it is an open sight an / m ✗ (n)\n",
      "-0.002028953001804029\n",
      "0.001464888560615718\n",
      "0.00036375913355668477\n",
      "-0.00220040667227947\n",
      "-0.0019978476203009188\n",
      "-0.0033226877547165856\n",
      "0.00040790597430670483\n",
      "-0.0017036538112858157\n",
      "-0.0018605763951993204\n",
      "0.0008378023387633216\n",
      "-0.0017656064766061186\n",
      "-0.0008234897854606793\n",
      "-0.0013023606362748685\n",
      "0.00017019898300832392\n",
      "-0.003192703149869608\n",
      "0.0016300122947094098\n",
      "0.002127462926432927\n",
      "-0.0019589078168710528\n",
      "0.003936994315487191\n",
      "-0.0025194137114886994\n",
      "0.0020973940794461465\n",
      "-0.0007865872425345533\n",
      "0.0020585727626665218\n",
      "0.0020526847554080407\n",
      "-0.0025562045946929957\n",
      "-0.002074611802348747\n",
      "-0.001188464640389908\n",
      "-0.0011639656429227596\n",
      "0.0016802141662843884\n",
      "-0.0012672729743845867\n",
      "-0.001934067800403616\n",
      "0.0015635475726374914\n",
      "0.0018813508635216747\n",
      "-0.0012846631435185774\n",
      "0.0024783105669946848\n",
      "-0.0013355907754176999\n",
      "0.0020062305929360313\n",
      "0.0019277312231834043\n",
      "-0.0017787072718778718\n",
      "0.0018786208209196353\n",
      "-0.0019508874354862704\n",
      "-0.0008688402124915617\n",
      "0.002028926477702725\n",
      "0.0020256720810503392\n",
      "-0.001365032703874114\n",
      "0.0005103593506465276\n",
      "0.003772369644284873\n",
      "-0.001883152336851962\n",
      "0.00048275947690132326\n",
      "-0.0012761734325789365\n",
      "200 0% (0m 6s) 4.2796  resign after all the attacks that had been made on him and he would meet parliament and defend hims / m ✗ (s)\n",
      "4.0160291204488496e-05\n",
      "-0.001259785542321118\n",
      "0.001970817786463963\n",
      "0.0017276442667990555\n",
      "-0.0018756543609081966\n",
      "-0.0013807164551777051\n",
      "-0.0008902591631905488\n",
      "-0.0015110898724885746\n",
      "0.0021304600180584443\n",
      "0.0019764360087411725\n",
      "-0.002172561955037955\n",
      "0.0015983024562938875\n",
      "0.00023852482108741024\n",
      "0.001755789117922596\n",
      "0.0019432469173743527\n",
      "0.001868643692811478\n",
      "-0.0013514069374264692\n",
      "-0.00028335137215640405\n",
      "0.0015523431908155694\n",
      "-0.0018868966664187525\n",
      "-0.0013072753696860562\n",
      "0.001844948827935955\n",
      "-0.0018837589577746783\n",
      "-0.0020621881216891236\n",
      "0.0019182526356477658\n",
      "-0.0014762283053659508\n",
      "-0.001239372454579335\n",
      "0.002122158263555468\n",
      "0.0003237297768019787\n",
      "0.0016872462933614218\n",
      "0.0019266976508031108\n",
      "-0.0009959229624159904\n",
      "0.0018665052299493834\n",
      "0.0019017303451160372\n",
      "-0.0019466786924495216\n",
      "-0.003280490082579496\n",
      "-0.002281148845940162\n",
      "-0.0020874604149005715\n",
      "0.0019460078731093067\n",
      "0.0019099984430051564\n",
      "-0.001803715274217882\n",
      "-0.0001896028852404752\n",
      "0.00027924692731248757\n",
      "0.0019255973619584366\n",
      "-0.00012286220179621998\n",
      "-2.3711227758571596e-05\n",
      "0.0002968171043921386\n",
      "0.0019158068669196393\n",
      "-0.00191725491764147\n",
      "-0.001240191670166868\n",
      "250 0% (0m 8s) 4.2803 early preferable either to or that roguish leer of makes a pretty woman heart lest by any means this / m ✗ (s)\n",
      "-0.001306356059874142\n",
      "-0.0017771973135480013\n",
      "8.030547697779333e-05\n",
      "-0.001745193757978103\n",
      "-0.0012845425491394558\n",
      "9.665329165220449e-05\n",
      "0.000790490609755834\n",
      "-0.0008428992826400583\n",
      "-0.0012728134489668752\n",
      "0.0018464960956395549\n",
      "-0.001759373001097242\n",
      "-0.0020248389834807423\n",
      "0.0005203994980255144\n",
      "-0.0010246054753634826\n",
      "-0.0008442347817456952\n",
      "8.204630023522785e-05\n",
      "-0.0010077451439825524\n",
      "0.002014929709604596\n",
      "-0.0020692552073846293\n",
      "-0.0013331837454398088\n",
      "0.002007365432968672\n",
      "0.0017296936549787145\n",
      "0.0006662111454351638\n",
      "0.0019949796689687493\n",
      "-0.0014068721184497812\n",
      "-0.0009473645504816941\n",
      "0.001893402978390052\n",
      "-0.002618180274068155\n",
      "0.0005159559459099738\n",
      "-0.000908478129891449\n",
      "-0.0013752123330066923\n",
      "-0.0008319108564118216\n",
      "0.0014334923297693314\n",
      "-0.00015352981605312732\n",
      "0.0016804366398404935\n",
      "0.0014569048117462347\n",
      "0.001945648073422901\n",
      "-0.002522231485656029\n",
      "-0.0008158580367249868\n",
      "0.0019937863495075037\n",
      "0.0013908756673686462\n",
      "-0.0020493247593340314\n",
      "-0.0012529702642933849\n",
      "-4.784994142156829e-05\n",
      "0.0014269114873879385\n",
      "-0.0013220197948383139\n",
      "0.0020332133108621198\n",
      "0.0017363472588308448\n",
      "-0.001765905060615941\n",
      "-0.0018113348807143603\n",
      "300 0% (0m 9s) 4.2961 general decay to be found in the old quarters of cairo and in a few years the tourist will only be a / m ✗ (a)\n",
      "-0.0007728060050237184\n",
      "-0.0031560558957899887\n",
      "-0.001903865244139935\n",
      "-0.0007402133364853292\n",
      "-0.0011070175171920271\n",
      "-0.0006437612646679469\n",
      "-0.001358600528949927\n",
      "0.0015878520984020927\n",
      "0.001776709596685827\n",
      "0.0003317515025908768\n",
      "0.0019357628069958388\n",
      "-0.0009025246167019829\n",
      "0.0019477574758205718\n",
      "-0.0017245925198747791\n",
      "0.0021298597195206492\n",
      "-0.0007363120812825252\n",
      "-0.0010754831646390406\n",
      "-0.0011556852029695475\n",
      "0.0017934302629022125\n",
      "0.00198598440706213\n",
      "0.001906699668185463\n",
      "0.0015281485147216056\n",
      "-0.0011806486152272921\n",
      "0.001797138152296096\n",
      "-0.0007984747650975343\n",
      "0.000220970893696798\n",
      "-0.0017658473661683605\n",
      "0.002426062776752197\n",
      "-0.0017519435880251621\n",
      "0.0016065489712281666\n",
      "0.0006731825257720869\n",
      "0.002087537930851757\n",
      "0.0003855235130109935\n",
      "0.001968857768227722\n",
      "-0.0010656670694507708\n",
      "0.001909816887907756\n",
      "-0.0011480942007624506\n",
      "-0.0008529608375917319\n",
      "-8.076939025269958e-05\n",
      "0.0017499991865543019\n",
      "0.0038398760339695137\n",
      "0.0014891115090900908\n",
      "0.0003814360935401606\n",
      "-6.311792272006844e-06\n",
      "0.001993534007664055\n",
      "-0.0009263823193405574\n",
      "-0.0020906190479988707\n",
      "0.0018733314067621576\n",
      "-0.0013310238793121931\n",
      "0.0014839157737427666\n",
      "350 0% (0m 11s) 4.2039 e study of the scriptures in our common english version his application of bible language to ordinar / m ✗ (r)\n",
      "-0.0008994392616542557\n",
      "0.0007180351174499444\n",
      "-0.001262376968617862\n",
      "-0.002072868966908309\n",
      "-0.0009285094202421407\n",
      "-2.2763615840887264e-05\n",
      "0.0007314233047536756\n",
      "-0.0018023872998668145\n",
      "-0.0009071558397301949\n",
      "0.0017770844159079036\n",
      "0.001969740590438196\n",
      "0.0019302029485372407\n",
      "0.0017948585518594573\n",
      "-0.0015849989684089683\n",
      "-0.00020633364012973\n",
      "-0.0009968214315418111\n",
      "-0.0013836025400338625\n",
      "0.00032025042089670053\n",
      "-0.001029429560691325\n",
      "-0.0015953068540368598\n",
      "0.0018713247431908775\n",
      "0.0013976085608999878\n",
      "-0.0015027803779559257\n",
      "-0.0015174106924620012\n",
      "-0.0013203144133414335\n",
      "-0.001390013473299756\n",
      "0.0016496024705222323\n",
      "-0.0012683183167678802\n",
      "-0.0014983734054284659\n",
      "-0.0020473719397638146\n",
      "0.0006097424720184763\n",
      "0.0016680158548856017\n",
      "0.0015533356477298588\n",
      "-8.849252766759963e-05\n",
      "-0.0017723503121745143\n",
      "-0.00204468329698132\n",
      "0.002159798641405336\n",
      "-0.001443173171560036\n",
      "0.0018161186494807524\n",
      "-0.0013347141910022287\n",
      "-0.0020012601008187747\n",
      "0.003958864070453899\n",
      "0.0017902145659685342\n",
      "0.0004610665115749313\n",
      "-0.00028181645236505237\n",
      "0.0017686363726439336\n",
      "-0.0020565578199967516\n",
      "5.787920619165776e-05\n",
      "0.0002610973034659625\n",
      "-0.0009591726445760396\n",
      "400 0% (0m 12s) 4.2696 he signatures of the councilors and of the members of the community who gave their consent namely al / m ✗ (l)\n",
      "0.003825175645116058\n",
      "-0.003429993005108878\n",
      "0.0015838020231282723\n",
      "-0.0015358687000132376\n",
      "-0.0026579770286803417\n",
      "-0.0010086625078646327\n",
      "-0.0021768868946115127\n",
      "-0.0015138076155557234\n",
      "-0.0013475663588476683\n",
      "-0.0020839849072358807\n",
      "0.001816561791967236\n",
      "0.0019642145175174375\n",
      "-0.0013844913915204982\n",
      "0.0004846216393906422\n",
      "-0.002553798247080158\n",
      "-0.0008757230214055112\n",
      "-0.00206863479023342\n",
      "0.0004980884224592141\n",
      "0.0007424873067001514\n",
      "0.0016589118873894526\n",
      "8.993102044174694e-05\n",
      "-0.0012503408935302662\n",
      "0.0016836396655769692\n",
      "-0.00012214173899668945\n",
      "-0.00021735071516609805\n",
      "0.0006577814776148327\n",
      "-0.0008965016749328536\n",
      "-0.0020011733539535004\n",
      "-0.001387704828679004\n",
      "-0.0007984339532640106\n",
      "0.0005825539233466348\n",
      "-0.0012237139770879812\n",
      "-0.0012392025358389236\n",
      "0.0017526024009147656\n",
      "-0.001108815065280322\n",
      "-0.0018355636912178452\n",
      "-0.0008260376610619014\n",
      "0.0019799086399051313\n",
      "0.002132703665735841\n",
      "-0.001219391434078787\n",
      "-0.0011676078045030625\n",
      "-0.003143802037049004\n",
      "-0.0016939475764506107\n",
      "0.0019914584767858623\n",
      "-0.0017962877869022176\n",
      "-0.001481481416259145\n",
      "-0.0010490779382432147\n",
      "0.0021822873304554735\n",
      "-0.001053999063042127\n",
      "-0.0005889531614821919\n",
      "450 0% (0m 13s) 4.2693 cally attached to this is a murderous device which we had often previously heard of but never till t / m ✗ (t)\n",
      "0.00226335153608484\n",
      "0.00013931721892787574\n",
      "0.0022810779510179513\n",
      "-0.002210290124649905\n",
      "0.0017504142096091413\n",
      "0.002183763406669176\n",
      "-0.0018354757604250316\n",
      "0.00030413323349684496\n",
      "-0.0018173825563689572\n",
      "0.0007704253259334104\n",
      "0.002000446108743864\n",
      "0.002104353885454713\n",
      "0.0020997962197034925\n",
      "0.004224135339010282\n",
      "0.0020266245372244363\n",
      "-0.0007224612309159606\n",
      "0.001994750361448777\n",
      "-0.0019433934774777117\n",
      "0.0021726564465333054\n",
      "0.0020814199626470464\n",
      "-0.002038127361182529\n",
      "-0.0018569467193443046\n",
      "0.0025955485450600835\n",
      "-0.0018985020191997215\n",
      "0.00214724933085797\n",
      "-0.0012276792311946838\n",
      "-0.0019610950626639256\n",
      "0.002091344109674459\n",
      "0.0017607578771270394\n",
      "0.0020393417131631397\n",
      "0.0020677817132427334\n",
      "0.0001067918135389534\n",
      "-0.0016863396125073316\n",
      "0.001740542870513978\n",
      "-0.002071847126412729\n",
      "-0.0008031353109873018\n",
      "-0.0017522714770435432\n",
      "-0.001141265552868087\n",
      "0.0007608478427353904\n",
      "-0.001218182502606524\n",
      "0.00022303151850713854\n",
      "-0.0017702605086744039\n",
      "0.00214645753452411\n",
      "-0.0009059836435043878\n",
      "0.0021710005642190666\n",
      "-0.0016678934579554827\n",
      "-0.0010090088071176007\n",
      "0.0020642491951211317\n",
      "0.002124756176551862\n",
      "-0.0018595565359228738\n",
      "500 0% (0m 15s) 4.3004 f from speech to say to speak see er logic def defending by words or arguments said or written in de / m ✗ (e)\n",
      "-0.0018402164156340606\n",
      "0.0021827936571027773\n",
      "-0.0019244569757766727\n",
      "0.0003335954406805952\n",
      "-0.0017734773928053116\n",
      "-0.0017600439061355722\n",
      "-0.0018493056695477184\n",
      "-0.0019279325229573374\n",
      "-0.0018809811741480054\n",
      "-0.0016142593741197142\n",
      "-0.0032000573100690877\n",
      "-0.0010414682919142049\n",
      "0.0002361653061672686\n",
      "0.0019775671096577963\n",
      "0.0020578596788130288\n",
      "-0.0005394568189174553\n",
      "0.0021382103647504813\n",
      "-0.0012623230637287819\n",
      "0.00020097862020154733\n",
      "-0.0015532548180250683\n",
      "-0.000702545671515592\n",
      "0.0007643274102251685\n",
      "0.0020668698096132643\n",
      "-0.001830730410585818\n",
      "9.228843508404805e-05\n",
      "0.0020862393734373263\n",
      "-0.0010617093850297799\n",
      "0.00027013837445608035\n",
      "0.0021607826156782306\n",
      "-0.0016334437634298316\n",
      "-0.0011256397698869158\n",
      "0.002159527062130462\n",
      "-0.002251412177607437\n",
      "-0.0016056652447166975\n",
      "0.001673875722805751\n",
      "-0.002343796976543966\n",
      "0.0020157513933778404\n",
      "-0.0018777162056717034\n",
      "-0.0018150702591442636\n",
      "-0.0016009032001840506\n",
      "-0.0017151367402718776\n",
      "-0.001561559588945327\n",
      "0.0021306738349617382\n",
      "0.002231349466330329\n",
      "-0.001605866432462938\n",
      "-0.0018961586742209102\n",
      "-0.0011196223977363862\n",
      "-0.0005165369416423593\n",
      "0.0006400101147368831\n",
      "0.0019076222579260393\n",
      "550 0% (0m 16s) 4.1976 le of the magistrates court urbane slightly stooped in shoulders high in forehead set in glance an o / m ✗ (o)\n",
      "-0.0017908359211571967\n",
      "-0.001908062034723379\n",
      "0.0022740300739102492\n",
      "0.0020525526027376784\n",
      "0.00013855182307803693\n",
      "-0.000579572168765724\n",
      "0.0018997711992220778\n",
      "0.0026346281985752396\n",
      "-0.0018467320458318004\n",
      "-0.0010590390369069336\n",
      "-0.0018005852759971075\n",
      "0.0006399713007658736\n",
      "-0.0012959307712063772\n",
      "-0.0006056813945822248\n",
      "-0.0004630372555839146\n",
      "0.0007545482439546558\n",
      "-0.0009690254643903162\n",
      "-0.0017614300519540882\n",
      "-0.00041174868496854367\n",
      "-0.0016639195461105039\n",
      "-0.001732063793931038\n",
      "0.0020832776924256113\n",
      "-0.0016005170391568124\n",
      "-0.00044508128440354233\n",
      "-0.0008070179900881158\n",
      "0.0004744311375943777\n",
      "-0.00044455511104282697\n",
      "0.0023235439067260943\n",
      "-0.0016009340318774434\n",
      "-0.0019994346360016346\n",
      "0.002517614660961759\n",
      "-0.0006267344359411342\n",
      "-0.0006937351793819269\n",
      "-0.000893168158686064\n",
      "0.002211866923830297\n",
      "0.00038795613058578704\n",
      "0.002347955254544065\n",
      "0.0021513010593034454\n",
      "0.0019506484314529282\n",
      "0.0005768804907951008\n",
      "-0.0007633059574547463\n",
      "-0.0007485339828289805\n",
      "-0.00046110599181811707\n",
      "0.001946063862967612\n",
      "0.0019483933152024124\n",
      "-0.0013611019638185284\n",
      "-0.0010752948822114472\n",
      "0.0022688890394790273\n",
      "-0.0007794856362804414\n",
      "-0.0008580893472972806\n",
      "600 0% (0m 18s) 4.2820 ructures but that the work of my ministry was to find the way to the hearts of men and to labor with / m ✗ (h)\n",
      "0.00244839630187349\n",
      "0.0009935911405170583\n",
      "-0.0010187906368959165\n",
      "-0.0008774933214131253\n",
      "0.0023454626654348387\n",
      "0.00043808000140913017\n",
      "-0.0008836032481398803\n",
      "-0.0016255897453753554\n",
      "-0.0016264134432355803\n",
      "0.002358410149903345\n",
      "0.0018066169730701076\n",
      "-0.0006441811358477156\n",
      "0.0020231288297783145\n",
      "-0.0014285069675628315\n",
      "0.0020061817034059126\n",
      "-0.0009484961399945369\n",
      "0.00041743448756281776\n",
      "0.0021824280881800606\n",
      "0.0006365904917466636\n",
      "-0.0015259192141112432\n",
      "0.002148156383663724\n",
      "0.0009426842766060428\n",
      "-0.0010731956061162118\n",
      "0.0022838077901897458\n",
      "-0.00105199843172335\n",
      "-0.0014127503642656913\n",
      "-0.0015148304188650208\n",
      "-0.0016097807587289181\n",
      "0.0011320529277052127\n",
      "-0.0011070596641686303\n",
      "-0.0016610264468161495\n",
      "-0.0010869852157193438\n",
      "0.004279622051441417\n",
      "-0.0009549037780060277\n",
      "-0.000459972722140628\n",
      "-0.001377492080920334\n",
      "0.0008927604943288203\n",
      "0.002305338569522919\n",
      "-0.000581344402358408\n",
      "0.0024376679697333536\n",
      "-0.0009085296603011106\n",
      "0.0019214707302221412\n",
      "0.0022661558391800785\n",
      "0.0010091562602793092\n",
      "0.0022024325113619847\n",
      "0.0021555574811488454\n",
      "9.91396938740674e-05\n",
      "-0.0016015030762782378\n",
      "0.0023119039634056926\n",
      "0.002133279792716325\n",
      "650 0% (0m 19s) 4.1906  to go so suddint and not to see you again and the other young gentlemen likewise seein you go away  / m ✗ ( )\n",
      "-0.0006132918473414073\n",
      "0.002069900359907312\n",
      "8.823317141443132e-06\n",
      "-0.001634132374121633\n",
      "-0.0011825019765954459\n",
      "0.0020184918849792677\n",
      "-0.001968579812506921\n",
      "0.00215359885321198\n",
      "0.0017813914688728782\n",
      "-0.001090755913251057\n",
      "-0.0016340074949280359\n",
      "-0.002456136909048834\n",
      "-0.0016801231330637045\n",
      "0.0005429552869730403\n",
      "-0.0025351045853392318\n",
      "0.00018752623276746538\n",
      "0.0008116123993217317\n",
      "-0.0011963360414470603\n",
      "0.0020985370719565632\n",
      "0.0019520807879645496\n",
      "0.001771958571289367\n",
      "7.256151061738048e-05\n",
      "0.0015117120864109046\n",
      "-0.0016903838558570972\n",
      "-0.0007897260081312363\n",
      "0.001917706867143959\n",
      "0.0018948796339871288\n",
      "0.0005232083075013827\n",
      "0.001989153156927048\n",
      "-0.002608361696406991\n",
      "0.0018868076166990988\n",
      "0.001453143103966964\n",
      "-0.000898859965967419\n",
      "-0.0021789594372851606\n",
      "-0.0013627869653883573\n",
      "0.00048588348948627735\n",
      "0.001986013335658232\n",
      "-0.0020554827464145664\n",
      "-0.002059830659213696\n",
      "-0.0019880495100459694\n",
      "0.0020111857782000586\n",
      "-0.0017765455542219089\n",
      "1.9425220861180037e-05\n",
      "-0.0017376061141937127\n",
      "6.543230598482497e-05\n",
      "-0.001368359889233256\n",
      "0.0006850574020615952\n",
      "-0.001969415263690516\n",
      "-0.0007911044576605075\n",
      "0.002032736143489061\n",
      "700 0% (0m 20s) 4.1903  of it the man safe enough said burgess who had just up in time to hear blount last words no he did  / m ✗ ( )\n",
      "0.002391776172270599\n",
      "0.00019617468006330463\n",
      "0.003958861046528428\n",
      "-0.0020232851868614565\n",
      "0.0017162709664103604\n",
      "-0.0013236324975708647\n",
      "0.0017694151538876213\n",
      "-0.002074958824393791\n",
      "0.0005228873197181128\n",
      "-0.000915639819630859\n",
      "-0.0009452326490398122\n",
      "0.0007437310552369791\n",
      "7.2700511391798894e-06\n",
      "0.0014629054953407827\n",
      "-0.0019667756575557638\n",
      "-0.0017572791377984676\n",
      "0.0014799882953391574\n",
      "0.0019909017949199526\n",
      "-0.000144228966517862\n",
      "-0.0017991891045889274\n",
      "0.0015221992164709264\n",
      "-0.0017488774631501391\n",
      "-0.0017229204607096538\n",
      "0.00205954194069366\n",
      "0.0019702062227019423\n",
      "0.0005169044769033626\n",
      "-0.0008110620206657759\n",
      "-0.0013151900239347647\n",
      "-0.0020780675751583266\n",
      "-0.0017804937881614746\n",
      "-0.0015051635812176334\n",
      "-0.0017952370010470287\n",
      "-0.0012545429193230873\n",
      "-0.0019953375856679445\n",
      "0.00041386610382604383\n",
      "0.0017494653163016294\n",
      "0.0018848691296224351\n",
      "-0.0014820865125667604\n",
      "-0.0013298117908939477\n",
      "0.00010355855950222592\n",
      "0.0020398347811165507\n",
      "0.0016994867585835849\n",
      "0.0019986850705178416\n",
      "0.00396498813904983\n",
      "8.24253969553268e-05\n",
      "0.0007692999635558473\n",
      "-0.0001325754944634383\n",
      "0.0019660436025197847\n",
      "-0.0013397761232206429\n",
      "-0.002012348119464158\n",
      "750 0% (0m 22s) 4.3019 ge that few if any could excel and who invariably put up at long s stationed at aldershot the colone / m ✗ (e)\n",
      "0.0019310038618403358\n",
      "9.477119991352367e-05\n",
      "0.0005576661824899243\n",
      "-0.0012077843192734583\n",
      "0.002442559162562946\n",
      "-0.001975205968023197\n",
      "0.0006511636871334159\n",
      "-6.293531538381636e-05\n",
      "0.0020509623418324407\n",
      "0.0005218903294132993\n",
      "-0.0020563790669253235\n",
      "-0.0017784895828832081\n",
      "-0.001789806352335721\n",
      "0.0014690178163696554\n",
      "-0.001428698677463397\n",
      "-0.0017931898310405703\n",
      "-0.001465688680798577\n",
      "0.001478430186090729\n",
      "-0.002092611875469441\n",
      "-0.0017332588697867302\n",
      "0.0006910654846252473\n",
      "-3.462524092012753e-05\n",
      "0.0004890318884728795\n",
      "4.626423502002153e-05\n",
      "0.004004996211808137\n",
      "-0.0019085680761005697\n",
      "7.617214898111846e-05\n",
      "-0.0012265503819575974\n",
      "0.0025417898171709585\n",
      "0.002030812514570546\n",
      "0.0008127471305315603\n",
      "0.0005843045471441433\n",
      "0.0015628307466457325\n",
      "-5.686577895513967e-07\n",
      "-0.0012990054881122648\n",
      "-0.0008334550448524936\n",
      "0.002065015033802381\n",
      "0.0014163973469766833\n",
      "-0.0017648607665214922\n",
      "0.0019307673607687481\n",
      "-0.001734923182037329\n",
      "-0.00197003839471821\n",
      "-0.0007451652249773066\n",
      "0.0019633223274453104\n",
      "-0.0020875467319322882\n",
      "-0.0008433029564881289\n",
      "-0.000994637394810205\n",
      "0.0004917273197715122\n",
      "-0.0013759327719497227\n",
      "-0.002130046031033783\n",
      "800 0% (0m 23s) 4.3044 d that other caravan where was it where were all caravans and all the bewilderment and all the false / m ✗ (e)\n",
      "0.0015139453681907444\n",
      "0.002037279289885313\n",
      "-0.001971435844414171\n",
      "0.0007972063430687348\n",
      "-0.0008143768680751173\n",
      "5.547964676536066e-05\n",
      "0.0017786619462319686\n",
      "-0.0009758777145511266\n",
      "0.0002050310878629058\n",
      "0.0019494547863881384\n",
      "-0.0020168262996380915\n",
      "-0.0013331653660865195\n",
      "-0.0013617632404663849\n",
      "-0.0008870454204983058\n",
      "0.0008245318286938808\n",
      "-0.001794356935022251\n",
      "-0.0012354449120551003\n",
      "-0.0018570334480046136\n",
      "2.492942326426384e-05\n",
      "0.0019460977409929137\n",
      "-0.000768396824025519\n",
      "0.0006203180423997867\n",
      "-0.0016787324224900868\n",
      "-0.0017912686518157528\n",
      "0.0006700307742583678\n",
      "-0.0017465058453201565\n",
      "0.0018738709747922744\n",
      "-0.0030807178330489737\n",
      "0.0021583130299657194\n",
      "0.0018466463214006912\n",
      "0.0020917228487218886\n",
      "0.0006824309144832785\n",
      "-0.001763916859558956\n",
      "0.0014989150913454763\n",
      "0.0014096194859778144\n",
      "-0.002083376729445585\n",
      "0.0018225047415940665\n",
      "0.0016720806340488337\n",
      "-0.0013499545359491605\n",
      "-0.000139896411847501\n",
      "-0.0012347506013325737\n",
      "0.00018613625831045977\n",
      "0.0006080911902734687\n",
      "-0.0007500813051631583\n",
      "-0.001902311241285537\n",
      "-0.0006695164914901908\n",
      "0.00216168730993041\n",
      "0.0024838537064365285\n",
      "0.0002699516711717198\n",
      "0.0020587116964208008\n",
      "850 0% (0m 25s) 4.1905  the dhartarashtras who was sensitive about his honour whose prowess was irresistible who was ready  / m ✗ ( )\n",
      "0.001826004288322941\n",
      "0.00044816502519737234\n",
      "0.002084632715431134\n",
      "-0.0018605774596584246\n",
      "0.00191414016430691\n",
      "-0.0013642134773420855\n",
      "-0.0008792182179448993\n",
      "-0.0019172611428258934\n",
      "0.0001208848135844931\n",
      "-0.001972028909881157\n",
      "0.002079713785413384\n",
      "-0.002038096892134883\n",
      "-0.0019246055464429423\n",
      "0.0016019621733228406\n",
      "0.0025919650487293278\n",
      "0.0020180824859634405\n",
      "0.00396389497286756\n",
      "0.0018192114218361088\n",
      "-0.0012146462869555286\n",
      "-0.0018909781749126553\n",
      "-0.001864373568675859\n",
      "0.0014941851185224508\n",
      "0.0019281411441351703\n",
      "-0.0019671892890849585\n",
      "0.0016204985830907959\n",
      "0.0005008337864320922\n",
      "0.0017837508200959085\n",
      "-0.0017860849440097804\n",
      "0.0005100403306654289\n",
      "-0.00120741453520129\n",
      "-0.0013334977760440514\n",
      "4.573792486825545e-05\n",
      "0.001531556793832961\n",
      "0.0019943884715410143\n",
      "0.0019574913312974673\n",
      "-0.001242075258899994\n",
      "-8.798341641497176e-06\n",
      "-0.003192020090544534\n",
      "-0.00018267250702216908\n",
      "0.0017983865662146437\n",
      "-0.0018098305367028056\n",
      "-0.0007883535936948627\n",
      "-0.0020646454753031063\n",
      "-0.001264439371812781\n",
      "0.0020130076204787906\n",
      "0.0018028274512126574\n",
      "-1.655155965860078e-05\n",
      "-0.0013762196084658729\n",
      "0.0019794871810787096\n",
      "0.0019397856423779003\n",
      "900 0% (0m 26s) 4.1905 o his temples dripping with sweat he crossed the basement to the little overlooking the garden that  / m ✗ ( )\n",
      "-3.345347212499461e-05\n",
      "-0.0008920665346053847\n",
      "-0.0021481968169218824\n",
      "-0.0009052767346549861\n",
      "-0.0020729398799981535\n",
      "-0.0011444962259885838\n",
      "-0.0008017654717127898\n",
      "-0.0017826567835051432\n",
      "-0.0020233515599820118\n",
      "-0.0019058590603246994\n",
      "0.002088839124047087\n",
      "-0.001964713236487753\n",
      "-0.0008480925285256624\n",
      "-0.0019091867973012322\n",
      "-0.0011458036752226564\n",
      "0.0018143235135899827\n",
      "0.00013572043254556077\n",
      "0.0003650716466283288\n",
      "0.0001623542990304705\n",
      "-0.00126404267100802\n",
      "-0.001250973256713861\n",
      "-0.001098093536882172\n",
      "0.0020625997712917232\n",
      "-0.002461133098410645\n",
      "0.001479620414615579\n",
      "-0.002050001070964952\n",
      "0.0020925057174149553\n",
      "-0.0014330978640065828\n",
      "-0.0018800615921797104\n",
      "0.0020521775860026514\n",
      "-0.0007780831968683122\n",
      "0.0006337677592168356\n",
      "0.001572614669950373\n",
      "-0.0012224768877126257\n",
      "-0.0016102552847144236\n",
      "-0.0011394107838787193\n",
      "-0.0011266571286814298\n",
      "-0.0023326424349171537\n",
      "-0.0018379120364833412\n",
      "-0.0011069139682180762\n",
      "0.0020469463536802734\n",
      "0.0019770110506229233\n",
      "0.0021490520689667614\n",
      "-0.0022907808419160014\n",
      "-0.0011817616861235225\n",
      "-0.0017619002502130277\n",
      "-0.0007639118283431778\n",
      "0.0019079039511241125\n",
      "-0.0007001685297209626\n",
      "-0.0010895206090613119\n",
      "950 0% (0m 28s) 4.2821 g the players and the games played by girls were of course different from those in use among boys th / m ✗ (h)\n",
      "-0.0010481847223522134\n",
      "0.00409369145518812\n",
      "0.0007937621022698627\n",
      "-0.0010837628752915496\n",
      "-0.0011037591954912995\n",
      "0.0019311366528933505\n",
      "0.0003928699513340572\n",
      "-0.0006418130529344812\n",
      "0.0019011107056372822\n",
      "0.0021656543797420325\n",
      "0.0009623788936122812\n",
      "0.00209124135573982\n",
      "0.0015380608517788774\n",
      "-0.0016139152755226538\n",
      "-0.0018560437183767486\n",
      "0.002087657480216998\n",
      "0.001864051678155565\n",
      "0.0022612965335285506\n",
      "-0.0011982992774165757\n",
      "-0.0006494377813913987\n",
      "0.00020471906246266602\n",
      "0.002193392074238937\n",
      "-0.0011186144181615232\n",
      "-0.0016196373272737707\n",
      "-0.0016999920071801011\n",
      "-0.0017539028915003474\n",
      "0.002192482552681757\n",
      "-0.0010445732298955401\n",
      "-0.0010259503384524027\n",
      "0.002301208121324616\n",
      "-0.0010057291962575488\n",
      "-0.0018203041795299413\n",
      "-0.0009550724743443151\n",
      "0.0022495744182610133\n",
      "-0.0005112815121439129\n",
      "-0.0016924773818516314\n",
      "0.0008745151941404461\n",
      "0.0008420435314161756\n",
      "-0.0008685636323012558\n",
      "-0.0022220887783772625\n",
      "0.00231762745659711\n",
      "-0.0015159265303196778\n",
      "0.002150334022329614\n",
      "0.0022962739939699772\n",
      "-0.0014561414053207433\n",
      "0.002330221505517205\n",
      "-0.001411925771191147\n",
      "-0.0009710816074953166\n",
      "-0.0009972372659872442\n",
      "-0.000981677435262951\n",
      "1000 1% (0m 29s) 4.2824 m unremitted care of an invalid during eight years poor as elijah when his only grocers were the rav / m ✗ (v)\n",
      "0.001860128418099044\n",
      "-0.0010764077800560767\n",
      "0.002850760500391708\n",
      "-0.001708670540957996\n",
      "0.00263301755798806\n",
      "-0.0011175068906668917\n",
      "-0.0018749604300470346\n",
      "-0.001047249035381781\n",
      "0.0022553302050785096\n",
      "-0.0009239925818377848\n",
      "-0.0015268468107195454\n",
      "0.0021050510472221673\n",
      "-0.0016755492594119348\n",
      "-0.0010946777556379572\n",
      "0.00015641725219933678\n",
      "-0.001900167412522552\n",
      "-0.001919656742439907\n",
      "0.00027757014224710774\n",
      "-0.0011114444969644866\n",
      "-0.0006202555185770842\n",
      "-0.0022021796606001565\n",
      "0.002330885681737088\n",
      "0.002287478431621498\n",
      "-0.0008923159625144339\n",
      "0.0020095650683741306\n",
      "-0.0010121334031032436\n",
      "-0.0017401063918748572\n",
      "-0.0009058475505675789\n",
      "0.001906231093455224\n",
      "0.002041932227552362\n",
      "-0.0017684565913885786\n",
      "-0.00091103922138841\n",
      "-0.0014606235294696568\n",
      "-0.0006028360227093577\n",
      "0.0006973606334561566\n",
      "-0.0009525868787549907\n",
      "-0.0009508013842922658\n",
      "-0.0017254624607578872\n",
      "0.0021243338477312523\n",
      "-0.0010133871441525277\n",
      "-0.0022191696883392398\n",
      "-0.0010050943304017734\n",
      "-0.0013542275720458963\n",
      "-0.0016352159374548036\n",
      "0.0023249233859806984\n",
      "-0.0010087453563622784\n",
      "-0.0010049121073333056\n",
      "-0.0018371273913977415\n",
      "-0.0008934449837693648\n",
      "-0.0017185783018704437\n",
      "1050 1% (0m 31s) 4.3035 te mechanisch wie im traum sie haben mich gerettet sie haben mich gerettet gott sei dank die liebe w / m ✗ (w)\n",
      "-0.0007835046723175532\n",
      "-0.001982250884654535\n",
      "0.002131066064775422\n",
      "0.0011813366504910272\n",
      "-0.001902676254090102\n",
      "0.0028791667816818467\n",
      "0.0022966086407742448\n",
      "-0.0010603307952825602\n",
      "0.004367355126863232\n",
      "-0.00059657215197359\n",
      "0.0018318563375763486\n",
      "-0.00044617840272098697\n",
      "0.0008870941257070053\n",
      "-0.0005154642187956693\n",
      "0.0006823053631854203\n",
      "0.0018276765732204159\n",
      "0.002453081092796433\n",
      "-0.0016066282824092337\n",
      "-0.0008244504972645395\n",
      "0.002234165372652863\n",
      "0.0005667046978125034\n",
      "-0.00029108329377169895\n",
      "0.0022944944340368423\n",
      "-0.0028808803430972196\n",
      "-0.00042865016016077617\n",
      "-0.00162514782161291\n",
      "-0.0012641730453944178\n",
      "0.00048068932714434576\n",
      "0.0023956293118605476\n",
      "0.0025809614284338367\n",
      "-0.0008103918461049298\n",
      "0.0021069347391209914\n",
      "-0.0016222782627910437\n",
      "-0.0007575131707161509\n",
      "-0.0009310828357791678\n",
      "0.0018044580091094442\n",
      "0.0023667602031535173\n",
      "-0.002916155972752521\n",
      "0.00221138761141082\n",
      "-0.0013886604164594918\n",
      "0.0018792148450669788\n",
      "0.002099988261212715\n",
      "-0.001654622161530922\n",
      "0.0022383235091502085\n",
      "-0.000639057123153125\n",
      "-0.0010438037890128649\n",
      "0.002230543725537798\n",
      "-0.0010465349346214792\n",
      "-0.0014020292639046195\n",
      "-0.0009046492701726416\n",
      "1100 1% (0m 32s) 4.2803 ellous transformation terror filled her eyes wild fear blanched her cheeks a numbing sensation almos / m ✗ (s)\n",
      "0.0003147806148096899\n",
      "-0.003023406079466079\n",
      "-0.0008721009938597035\n",
      "0.001079944360041718\n",
      "-0.0003637323780466828\n",
      "0.0007972606569747465\n",
      "0.0019635788267097776\n",
      "0.004191497094031077\n",
      "0.0023570732511380976\n",
      "-0.0009316821866243719\n",
      "-0.001584509847313953\n",
      "-0.0008825024400051507\n",
      "0.002336034657339947\n",
      "0.0022213614789551306\n",
      "-0.0005660465626055322\n",
      "-0.001724955062787109\n",
      "0.002134692022997847\n",
      "-0.0019172249171810485\n",
      "-0.002125432535043048\n",
      "0.0022719425991626907\n",
      "-0.001862332532150457\n",
      "0.0017761042153750795\n",
      "0.0022161633931176428\n",
      "0.0001320297840403939\n",
      "-0.0018017146172884524\n",
      "0.002731820854152911\n",
      "0.0025719008533046095\n",
      "0.002233786614118244\n",
      "-0.0005168471415014642\n",
      "-0.0015409580250950183\n",
      "-0.0017041029813354147\n",
      "-0.0010228555436006537\n",
      "0.0021122363070606165\n",
      "0.0016918205024545052\n",
      "5.820359282482368e-05\n",
      "0.0001962546660757014\n",
      "0.0021900605115360294\n",
      "0.001610319404767968\n",
      "-0.0007488527754958285\n",
      "0.0020957966708495257\n",
      "0.0021041701540976954\n",
      "0.0007024871423535473\n",
      "-0.0017121038221395712\n",
      "-0.0007116525630728454\n",
      "0.0020420343446043154\n",
      "0.0007784841886123717\n",
      "-0.0014164346986427767\n",
      "0.001967802363121024\n",
      "0.0007157625460662009\n",
      "-0.003361751337596669\n",
      "1150 1% (0m 34s) 4.3379 avagance in lace ajustements barbes collerettes volants quilles coëffes of argentan angleterre and p / m ✗ (p)\n",
      "-0.0013257611502864308\n",
      "-0.0009719845523401827\n",
      "0.00011063814576212083\n",
      "0.0003551240667901967\n",
      "-0.0018304031470414706\n",
      "0.0038315737189476284\n",
      "-0.0015449643684153913\n",
      "-0.0012304814363630623\n",
      "-0.0007840790693226518\n",
      "-0.003384743406221913\n",
      "-0.0018559876209557347\n",
      "-0.0008667748323474\n",
      "-0.002024349277903459\n",
      "-0.0017868345430817056\n",
      "0.002101984937494389\n",
      "0.002099570610982565\n",
      "0.0019555081495973847\n",
      "-0.0016078175991879884\n",
      "-0.001745574383467119\n",
      "-0.0011919703086178124\n",
      "-0.000824731708800791\n",
      "-0.0010429666049381892\n",
      "0.0015412005735380707\n",
      "-0.0010795540778557322\n",
      "0.0021427919705443443\n",
      "0.00022598448781199765\n",
      "-0.0025297725280447603\n",
      "-0.0017340820324334982\n",
      "-0.0007449327270814821\n",
      "-0.0011012770199171074\n",
      "0.0017720008774741447\n",
      "-0.0007436295614072774\n",
      "-0.0016758948292031617\n",
      "-0.0011668030671063145\n",
      "-0.0018523886757136343\n",
      "-0.0011151854200381617\n",
      "-0.001687696485114798\n",
      "-0.0006585038161894263\n",
      "0.0007648694326790051\n",
      "-0.001848179691684132\n",
      "-0.0006231626388238654\n",
      "0.00206644271736256\n",
      "0.00027470446477820265\n",
      "0.00034976543025744267\n",
      "-0.0011891544792492492\n",
      "-0.0007131382931279684\n",
      "0.0022335270334431223\n",
      "-0.0010661267547039943\n",
      "-0.003054305993204831\n",
      "-0.001778345713513596\n",
      "1200 1% (0m 35s) 4.3020  of the wild cherry bark the patient is placed facing the sunrise and the doctor taking the medicine / m ✗ (e)\n",
      "0.00028672846198660173\n",
      "0.0022165726890788773\n",
      "-1.1338640243468978e-05\n",
      "0.0017329648997344571\n",
      "0.0020325814370196482\n",
      "-0.0006931753086591164\n",
      "0.0005899342786755413\n",
      "0.0022184171665640684\n",
      "0.002027773815822892\n",
      "-0.0006987309061545766\n",
      "-0.0012069691531507998\n",
      "-0.001099425711839408\n",
      "-0.0015917186720417476\n",
      "-0.000614492985777898\n",
      "-0.0017404338562877764\n",
      "0.002250027759686135\n",
      "-0.0006910126477251421\n",
      "0.0006412583804530914\n",
      "-0.0014810882069351272\n",
      "-0.0014935563757821901\n",
      "-0.0018228345149496894\n",
      "-0.0009488936221527522\n",
      "0.0020519373815643394\n",
      "-0.0016945515099170416\n",
      "0.0023301713855827244\n",
      "0.002167785295937835\n",
      "-0.0010861371014634358\n",
      "-0.0005724408544266757\n",
      "-0.00040316805103313147\n",
      "-0.0005800352381462592\n",
      "-0.0009428023458832591\n",
      "0.0021711564020324425\n",
      "0.004291351377373159\n",
      "0.002329468798010992\n",
      "0.00021102186185387173\n",
      "0.002144459144456712\n",
      "0.0009353277821816663\n",
      "0.0019266400134166917\n",
      "0.0003358192123897319\n",
      "-0.0017169865871071444\n",
      "-0.0009345343506073911\n",
      "-0.0014257202628881471\n",
      "0.001775374945592073\n",
      "0.0003441886244657244\n",
      "-0.0005210515917050684\n",
      "0.0023891647924437487\n",
      "-0.0014597667181642515\n",
      "-0.0016333608377892272\n",
      "0.00235788719572097\n",
      "0.001972655881380264\n",
      "1250 1% (0m 37s) 4.2001 second position and bend towards it wait a whole bar one polka step with right foot to the right tur / m ✗ (r)\n",
      "0.00035036129254109594\n",
      "0.0006896942391524108\n",
      "0.002159201256763721\n",
      "0.0021444349991432687\n",
      "-0.0015741226324026414\n",
      "0.0042683157428026475\n",
      "-0.0015037512356727845\n",
      "-0.0015201764825119313\n",
      "-0.0030258170776608917\n",
      "0.002706564403730849\n",
      "0.00036981885121542546\n",
      "-0.0010307111375675304\n",
      "-0.0014971762290111323\n",
      "-0.0006822192916082215\n",
      "-0.0006922600489715769\n",
      "0.0001633642175068728\n",
      "-0.0010233167837007673\n",
      "-0.0010513728512103748\n",
      "0.0019006065201843947\n",
      "-0.0006999021522911542\n",
      "0.0020285943254658156\n",
      "0.00037860546978005227\n",
      "0.0002366810266846986\n",
      "-0.0011162666043683378\n",
      "0.00038935676558243815\n",
      "-0.0005948694860897774\n",
      "0.000615282206955392\n",
      "-0.0018741852504855216\n",
      "-0.0015486759170790232\n",
      "-0.0014838220173147287\n",
      "-0.0006163109033789638\n",
      "-0.0010192553083593348\n",
      "-0.001833761084501534\n",
      "0.0006495746990363149\n",
      "-0.0015585884361771218\n",
      "-0.0021379690386240935\n",
      "-0.0015337435882668282\n",
      "0.0022733966054872823\n",
      "-0.0018227542201725566\n",
      "-0.0011574529567532632\n",
      "-0.001027721135316323\n",
      "-0.00150172016183997\n",
      "0.00227076483970981\n",
      "-0.00213374995044896\n",
      "-0.0022185260932831574\n",
      "0.0017824821699839732\n",
      "-0.0016383102749142064\n",
      "-0.0011670796676519213\n",
      "0.002312893840003938\n",
      "0.00026748614128774273\n",
      "1300 1% (0m 38s) 4.2444 in the accompanying figure which represents the mexican goddess of death teoyaomiqui the image is ni / m ✗ (i)\n",
      "0.00023944465563399686\n",
      "0.002173544187083598\n",
      "-0.0005559995053220357\n",
      "-0.0015006044942114938\n",
      "0.002227788513725071\n",
      "-0.0014256268554467266\n",
      "-0.0017159426954097001\n",
      "-0.0011344039856729937\n",
      "-0.0013660883832493365\n",
      "-0.00145126380688268\n",
      "-0.0028977670940947553\n",
      "-0.0008080970101016494\n",
      "0.0011608767627299676\n",
      "0.0005206666188955766\n",
      "-0.001078668999001109\n",
      "-0.0004714742754953205\n",
      "0.004354019909831031\n",
      "-0.001465228726408363\n",
      "-0.0009436874965167708\n",
      "-0.0014130372304883565\n",
      "0.0021936627861937064\n",
      "-0.0005584395096059902\n",
      "0.002333298205886458\n",
      "0.0006700431898006287\n",
      "0.002169576231093484\n",
      "0.00019156273069667606\n",
      "0.0018007415103207247\n",
      "-0.0015376798611431153\n",
      "-0.0028848621475198455\n",
      "-0.0016845116756658285\n",
      "-0.001071778427434139\n",
      "0.002027682571399264\n",
      "0.002140072334673948\n",
      "0.002108612516692282\n",
      "0.0022115058996355907\n",
      "-0.000675821528525411\n",
      "-0.0008815071779663675\n",
      "0.0002050822367440086\n",
      "-0.001026919633704465\n",
      "0.0004311063690613792\n",
      "0.002076277409711891\n",
      "-0.0016734936914264975\n",
      "-0.0009117685657844266\n",
      "0.0009400664720958518\n",
      "-0.0013882205569471229\n",
      "0.0004543835444215383\n",
      "0.002265033952120049\n",
      "0.0007929962588408002\n",
      "0.002193601800941608\n",
      "0.0024160156524136445\n",
      "1350 1% (0m 40s) 4.1894 la electricidad de vuestros sentimientos pero decirlos en toda su verdad difícil muy difícil porque  / m ✗ ( )\n",
      "-0.0014033382768810498\n",
      "-0.0014261529886171465\n",
      "-0.002069288327166685\n",
      "0.002439427216421458\n",
      "0.002413299993053647\n",
      "0.0024502541815927537\n",
      "-0.00037931029949955786\n",
      "-0.0008595862258506393\n",
      "-0.0014300195318015796\n",
      "-0.0015692140003434052\n",
      "-0.000468550134049478\n",
      "0.0019427273019958502\n",
      "-0.00038177396072827663\n",
      "0.0022609675793179296\n",
      "0.002413624715370738\n",
      "-0.0005497645324744616\n",
      "-0.0014110577221333187\n",
      "0.0006883882838051025\n",
      "0.002173284503849654\n",
      "-0.0009018689281217185\n",
      "-0.0007669894327820004\n",
      "0.0018786722896033392\n",
      "0.002350913150361289\n",
      "0.0010032050669207537\n",
      "0.0008790419288269846\n",
      "-0.001671249714748524\n",
      "-0.0009100623910979488\n",
      "0.002145211970723565\n",
      "-0.001691146594944376\n",
      "0.0023393484127499087\n",
      "-0.0009078678546567132\n",
      "0.002309468965283168\n",
      "-0.0005921111461301698\n",
      "-0.001650102426019484\n",
      "-0.0018210624613113346\n",
      "0.0020976317523624666\n",
      "0.0025468549861038525\n",
      "-0.0010241401556126684\n",
      "0.002049937883384423\n",
      "0.0005676978526368004\n",
      "0.004120409009790077\n",
      "-0.001197936003040051\n",
      "0.002156519643127769\n",
      "-0.0007159420547556972\n",
      "0.0020398065705527213\n",
      "-0.0006559207134628764\n",
      "0.0007076672682559126\n",
      "-4.087956228304712e-05\n",
      "0.0038676565495295023\n",
      "-0.0013082898077899086\n",
      "1400 1% (0m 41s) 4.2821 ets were immediately passed to him and he and the constable entered the tent opposed as he was to th / m ✗ (h)\n",
      "-0.0008117644312772565\n",
      "-0.001263152481492974\n",
      "-0.0009312660902825454\n",
      "0.0001706352938609934\n",
      "-0.0012000785262783475\n",
      "-0.0013406697893305064\n",
      "-0.0007754971189715132\n",
      "-0.001268368200679687\n",
      "-0.0020971633771835196\n",
      "7.308795278604396e-05\n",
      "5.8414900937497904e-06\n",
      "-0.0020709675972197528\n",
      "-0.001738562953580769\n",
      "-0.0009057528802181303\n",
      "0.0007086323152435403\n",
      "0.0023651931583548724\n",
      "-0.0006780460235980834\n",
      "0.004005879293669884\n",
      "-0.0018315993352043536\n",
      "0.0038939847582261933\n",
      "-0.0021139492794977344\n",
      "0.001502073945101684\n",
      "0.0005152362728451654\n",
      "0.0019548708680376947\n",
      "-0.001290527285585652\n",
      "0.0002729501287686842\n",
      "0.0005891871678414262\n",
      "-0.0025780353588626403\n",
      "0.001767165783543495\n",
      "-0.0013254671564831566\n",
      "0.00014276175974026195\n",
      "-5.944317532841081e-05\n",
      "0.0018741163109747827\n",
      "0.0019506930079557783\n",
      "-0.0014327577359338484\n",
      "-0.0020252135299754226\n",
      "0.0016118060122639055\n",
      "-0.002036465125786896\n",
      "-0.001318452199080028\n",
      "0.001956816720231208\n",
      "-0.0008970601202001605\n",
      "-0.0012821502268774987\n",
      "-0.0033196551001868913\n",
      "0.0020232659733125935\n",
      "-0.0020655054107063253\n",
      "0.0005123225481749871\n",
      "-0.001013548587813523\n",
      "-0.0017429266734765858\n",
      "0.001949356756113102\n",
      "0.001953379181282966\n",
      "1450 1% (0m 43s) 4.1926 have been speaking of you i am anxious to engage you a governess well mamma and will weston be so go / m ✗ (o)\n",
      "-0.0018122990989746512\n",
      "-0.0008592491781017064\n",
      "0.00196372687693544\n",
      "-0.0012710791310473757\n",
      "-0.0019731859503824833\n",
      "8.345553438332542e-05\n",
      "0.004020621406646524\n",
      "0.001970730700690093\n",
      "-0.0011866461315250265\n",
      "0.0018052479241102426\n",
      "0.0014222608602371678\n",
      "-0.0008012770527049684\n",
      "-0.0018847565254775656\n",
      "-0.0021138157343412733\n",
      "-0.001991050046062065\n",
      "0.0019846387792484543\n",
      "-0.0020481405298032607\n",
      "-0.0019922134603559127\n",
      "-0.001098845150415112\n",
      "0.0017098030139897913\n",
      "-0.0020482315944877205\n",
      "0.0005814102827225442\n",
      "-0.0011630155369433404\n",
      "0.0006647437506293041\n",
      "-0.0007191353643864473\n",
      "-0.0014362791783126827\n",
      "0.0020516969820589814\n",
      "0.0020666687906430725\n",
      "-0.0012364277398859425\n",
      "5.252766297070277e-05\n",
      "0.0016055335306630059\n",
      "4.4688901528644465e-05\n",
      "-0.0012762344904783396\n",
      "0.0001688694343279229\n",
      "-0.0020586827937754126\n",
      "0.000715261552682589\n",
      "-0.0008807214874564651\n",
      "0.002098108550252026\n",
      "0.0019451714642894913\n",
      "-0.0008143951976449793\n",
      "0.002130492291680358\n",
      "-0.0020377877853245685\n",
      "-0.0031632853160576957\n",
      "-0.0008143110536100173\n",
      "-0.0023020763370678876\n",
      "-0.0018187268139525647\n",
      "0.0017035744591168689\n",
      "0.00010545231376782316\n",
      "0.000999807366618366\n",
      "-0.0011076130278819818\n",
      "1500 1% (0m 44s) 4.2820 one mad leap from the top and disappeared in a cloud of spray and mist two thousand feet below furth / m ✗ (h)\n",
      "-0.0010963521983742286\n",
      "-0.0009537890936366644\n",
      "0.0002141431026206897\n",
      "9.12305462457963e-05\n",
      "-0.0017219437816547722\n",
      "0.0003343659073508365\n",
      "-0.0014416905112837886\n",
      "0.002360417208914306\n",
      "0.0019164526297165418\n",
      "0.00024842631145396976\n",
      "0.002494370216123226\n",
      "-0.0024824993996810374\n",
      "-9.736428470238923e-05\n",
      "-0.0011625881324635046\n",
      "-0.0015968979435207475\n",
      "-0.0015825044973653835\n",
      "0.0016366287774063348\n",
      "-0.0017801146743294527\n",
      "0.0008574603253842239\n",
      "0.0026753119591463592\n",
      "-0.0010763840046422446\n",
      "0.00012543574677387204\n",
      "-0.0017489977255002176\n",
      "0.002286178372860076\n",
      "-0.0010372374523592298\n",
      "0.0018054221520045766\n",
      "0.0007870489013175608\n",
      "0.0025325788636740287\n",
      "-0.0018059656810106017\n",
      "0.0018400070223740517\n",
      "-0.0012241429233217638\n",
      "0.0021279177290362827\n",
      "0.004168396470080132\n",
      "-0.0016285530564634498\n",
      "0.0026317144565443096\n",
      "0.0021149553932579834\n",
      "-0.0006604181594905834\n",
      "0.002124084108165114\n",
      "-0.0017120938030135702\n",
      "-0.0006673235198589311\n",
      "-0.0018705070849333871\n",
      "9.880436234288581e-06\n",
      "-0.0017121322518703352\n",
      "-0.0017806921324358682\n",
      "0.0001910534179666301\n",
      "0.0003576548080512776\n",
      "0.001552568993557768\n",
      "0.0018578757066802232\n",
      "-0.0011013991575926918\n",
      "0.00034771845457795547\n",
      "1550 1% (0m 46s) 4.2393 même dans sa conception du péché telles sont les qualités et les défauts de que nous retrouvons avec / m ✗ (c)\n",
      "-0.0012033223017874906\n",
      "-0.0006287604612580655\n",
      "0.0021767747719071417\n",
      "0.00196202029192058\n",
      "0.0018719144032012802\n",
      "0.001478993362176162\n",
      "-0.0010859452615444298\n",
      "0.0020886419986160254\n",
      "0.002072124077965254\n",
      "0.0019938549814484674\n",
      "0.0019340437968775603\n",
      "-0.00176485749986377\n",
      "0.001824345895725249\n",
      "-0.0017219309497456814\n",
      "-0.001964006184694833\n",
      "-0.001958337563638196\n",
      "0.0003763528083695622\n",
      "-0.001366814475489725\n",
      "-0.0008301329299016391\n",
      "-0.0011951600664258932\n",
      "-0.0011023838357214766\n",
      "0.0040169116196409616\n",
      "-0.001987424284527667\n",
      "0.002066727468568147\n",
      "-0.0008517093636223882\n",
      "-0.0033188235543347155\n",
      "0.002053724013440089\n",
      "-0.0008564990058098354\n",
      "-0.0012522004174378432\n",
      "0.0006202740914773297\n",
      "-0.0006404999654896493\n",
      "0.0020109291608761404\n",
      "-0.0019600712682936727\n",
      "-0.002070997559912219\n",
      "0.0019817560089341046\n",
      "0.004074295002700873\n",
      "0.0018148835728453994\n",
      "-0.0019866610599643397\n",
      "0.0015426685288371655\n",
      "-0.0016656540432398725\n",
      "-0.0012349768470371891\n",
      "0.0008283359612485941\n",
      "-0.0013770628650019712\n",
      "0.0020083114658747125\n",
      "0.0017014481266480197\n",
      "0.00173829527368069\n",
      "0.001910967557982729\n",
      "-0.0020595076583594663\n",
      "-0.0013141538617235382\n",
      "-0.0015008107655416492\n",
      "1600 1% (0m 47s) 4.2856 mme il toujours un peu timide dans les salles de bal il toujours ennuyé il jamais eu pour une dame d / m ✗ (d)\n",
      "-0.0008059654669917149\n",
      "-0.000896979206981674\n",
      "-0.0031835095878671726\n",
      "0.0018592126464616887\n",
      "-0.0009226299738368804\n",
      "0.0019790557910146223\n",
      "-6.149648341563507e-05\n",
      "0.0003568215139575226\n",
      "-0.0018114386333226984\n",
      "-0.0012957893867427406\n",
      "-0.0014409176237412114\n",
      "-0.001559023087564726\n",
      "-0.002544676364411136\n",
      "-0.0012985374433369112\n",
      "-0.0008503673400101774\n",
      "0.0014997918882450334\n",
      "-0.0012622215218409394\n",
      "-0.0008667473581522034\n",
      "-0.0017090314631319492\n",
      "-0.001331646578967255\n",
      "0.002046515149321526\n",
      "0.0018611216733523395\n",
      "0.0023253590633490195\n",
      "-0.0032839092606699316\n",
      "0.00043710573273195164\n",
      "0.00175395228749059\n",
      "0.00401834555338576\n",
      "0.0005295426605716469\n",
      "0.0018796966996409703\n",
      "-0.0024967090360956956\n",
      "-0.0017554086358956833\n",
      "-0.0017499663568742163\n",
      "-0.003212148515909008\n",
      "0.0018151989129765178\n",
      "-0.0019389714564060634\n",
      "0.0039787662676611935\n",
      "-0.0011654675384492053\n",
      "-0.0011397336526722812\n",
      "-0.0010894472147083556\n",
      "-0.0006262256680617806\n",
      "-0.0011445933362045357\n",
      "-0.0019314172731367263\n",
      "-0.0016936020125855322\n",
      "0.0040857483185594845\n",
      "-0.0019282012467959075\n",
      "-0.001655558559034126\n",
      "-0.0006618934228484474\n",
      "-0.0015372698989658817\n",
      "-0.0017025666405758866\n",
      "0.002175070071586155\n",
      "1650 1% (0m 49s) 4.1905 orning in visiting the cavern beneath the fall the guide recommended my companion and myself to set  / m ✗ ( )\n",
      "0.0006893429000814355\n",
      "-0.0011772638432825666\n",
      "0.0019013499708922244\n",
      "0.00017347315450313983\n",
      "0.00021699484843576422\n",
      "0.0005778860868912994\n",
      "-0.0015737176306300504\n",
      "0.0009989586794424132\n",
      "-0.0010825959864352863\n",
      "0.0017078126077070266\n",
      "-0.0017293374264962524\n",
      "0.002147470402838997\n",
      "0.00043780449878058625\n",
      "0.0019456922000363197\n",
      "0.0007652358910824608\n",
      "-0.0011316205087479048\n",
      "0.0002956766047313708\n",
      "-0.0011919942419155172\n",
      "-0.0011083933002404012\n",
      "-0.000779580912958544\n",
      "0.0004159557154243265\n",
      "-0.0005914886642658101\n",
      "0.0006536470509507786\n",
      "0.0022393422654554407\n",
      "0.0008098909740349991\n",
      "0.0021710169900958642\n",
      "0.0019059262024947732\n",
      "0.002181439299309751\n",
      "-0.0017498366746442617\n",
      "-0.0018549518825861366\n",
      "-0.0015459313007082087\n",
      "-0.0019119283537666343\n",
      "0.0019932483111020083\n",
      "-0.0030332689906884536\n",
      "-0.0010515609911206647\n",
      "0.004227541831444803\n",
      "0.0010056368428990048\n",
      "-0.0017383874589307624\n",
      "-0.001787390143996509\n",
      "0.0022173572054138557\n",
      "0.000769367463462789\n",
      "-0.001025941647632811\n",
      "-0.0006845234503916053\n",
      "0.002214163226080923\n",
      "0.00026789483277614434\n",
      "-0.0014322408966169764\n",
      "-0.0014849530309583026\n",
      "-0.000925469042652699\n",
      "-0.00162898760399674\n",
      "-0.0009573724458526167\n",
      "1700 1% (0m 50s) 4.2803 the apparatus for presenting all three positives lighted through their coloured glasses to the eye s / m ✗ (s)\n",
      "-0.000991204780934285\n",
      "0.0021091247244375\n",
      "0.001760582440595515\n",
      "0.0006571159023098794\n",
      "-0.0006127590853198528\n",
      "-0.0005176041705589329\n",
      "-0.001427087527702653\n",
      "-0.000489249863864949\n",
      "-0.0005630204334710898\n",
      "0.004264802713481813\n",
      "0.0022859881086084166\n",
      "0.001960349481459789\n",
      "0.0020180499889700942\n",
      "-0.0012634973346516976\n",
      "0.0001311377801602731\n",
      "-0.0016686416602458287\n",
      "-0.0011030085001245693\n",
      "0.0021450905394626296\n",
      "-0.0019323538067546053\n",
      "-0.0016040880525612922\n",
      "0.0021557642701129642\n",
      "-0.0011534564646945022\n",
      "0.000863567457972364\n",
      "0.0006966771617721856\n",
      "0.00215008938952152\n",
      "0.002150687725123751\n",
      "-0.0018143303174389391\n",
      "-0.001610241699271986\n",
      "0.0022713098395599485\n",
      "-0.0015408740215872574\n",
      "-0.0030791747052209273\n",
      "0.001709053688991491\n",
      "-0.0017244133417805285\n",
      "-0.0015835419020325536\n",
      "-0.0010584670443695987\n",
      "0.0042273537008928885\n",
      "0.00037240501907914725\n",
      "-0.0015558727718235354\n",
      "-0.0010633993299181688\n",
      "-0.0010095890373341687\n",
      "-0.0023817756407522317\n",
      "-0.001008590918807506\n",
      "-0.0010653074233911153\n",
      "-0.0009952664699423575\n",
      "0.0020317515625178917\n",
      "-0.0018181485132446606\n",
      "-0.000651492572780854\n",
      "0.0022010533671836807\n",
      "0.001837795435774836\n",
      "0.001855814645117554\n",
      "1750 1% (0m 52s) 4.1987 n vous au moins autant moi votre intérêt le fait naître et je ne vois pas comment mes circulaires po / m ✗ (o)\n",
      "-0.0011625579000264508\n",
      "-0.0012116289358719001\n",
      "0.004154761947697316\n",
      "-0.0018880246054879812\n",
      "0.0021973552359154935\n",
      "-0.0019528586085909572\n",
      "-0.0015493380773828336\n",
      "0.0019063371278530417\n",
      "-0.002145756728198722\n",
      "-0.0018642372886264191\n",
      "-0.0006723960915960836\n",
      "-0.0024571309601210123\n",
      "0.0021083347505120587\n",
      "0.000391288091449421\n",
      "-0.0006162652730875295\n",
      "-0.0010782327544257564\n",
      "0.00013192645415041615\n",
      "-0.0006191472923793295\n",
      "-0.001581435641188983\n",
      "-0.0015672639859184712\n",
      "0.0005945173833095396\n",
      "0.0009157016409368224\n",
      "0.000187369707366436\n",
      "-0.0005223409617080288\n",
      "-0.0015891077855682556\n",
      "-0.0011158056158276919\n",
      "0.0018827610761630031\n",
      "0.0023356886315817893\n",
      "-0.000545076281059903\n",
      "-0.0022699792045812184\n",
      "0.0009826744385542374\n",
      "0.0002983909013046515\n",
      "-0.0014751298102780586\n",
      "0.00202557604300474\n",
      "0.0017926460302878922\n",
      "8.481733878365483e-05\n",
      "-0.0009331532098359463\n",
      "-0.001723603392216111\n",
      "-0.0010278411562198442\n",
      "-0.0011145067324175029\n",
      "0.000885444550281056\n",
      "0.00012610787947048285\n",
      "0.0020510386737521147\n",
      "0.0021334366753623657\n",
      "-0.000556415601610627\n",
      "0.00030129837864031894\n",
      "0.0024709902079801394\n",
      "-0.0018295722278824922\n",
      "0.000909970303143437\n",
      "0.0019544584148799005\n",
      "1800 1% (0m 53s) 4.1976 et cap and remained uncovered whilst he sent into the town for an old one poor emperor thought one o / m ✗ (o)\n",
      "0.0021677275436909615\n",
      "0.0004066453843638851\n",
      "0.00193622566840157\n",
      "0.00018778489204099302\n",
      "-0.0006711214337997429\n",
      "-0.003083537040607237\n",
      "0.0022319264131604177\n",
      "0.00032813140670659435\n",
      "-0.0016481899632956876\n",
      "-0.000493506864982618\n",
      "-0.0006970795577677935\n",
      "0.0001529015250252841\n",
      "0.002327446664095456\n",
      "-0.0017100442098108015\n",
      "-0.000575778214501721\n",
      "0.002271263729043821\n",
      "-0.0011524524644655754\n",
      "0.0023033614801273583\n",
      "0.0004015165624956518\n",
      "-0.0014970021422255897\n",
      "0.00091276212847749\n",
      "0.0017221195411512291\n",
      "0.0008858481253971595\n",
      "-0.0017548986433547076\n",
      "-0.0016204842623595284\n",
      "-0.001692949121987447\n",
      "-0.002974328402183063\n",
      "0.00019106003318036802\n",
      "0.002185761274570458\n",
      "0.002274885940170085\n",
      "0.0005163579081778891\n",
      "-0.0007801536513747376\n",
      "-0.0006087532633349269\n",
      "-0.0011979981939126139\n",
      "-0.001764408584081556\n",
      "-0.0008812569923743463\n",
      "-0.0009965605877668704\n",
      "-0.0005191811783077926\n",
      "0.0023413362541722382\n",
      "0.002006077234510295\n",
      "0.002208498504490203\n",
      "-0.0011185893202078634\n",
      "-0.0017901197153805948\n",
      "-0.0006758248843717618\n",
      "-0.0017533784187384605\n",
      "0.0023974290160236056\n",
      "0.0021986835822874196\n",
      "0.0007450065091678948\n",
      "-0.00185891964424445\n",
      "-0.001799966385327867\n",
      "1850 1% (0m 54s) 4.3030 g still kept theirs in his own custody there are said to have been eleven hundred and fifteen castle / m ✗ (e)\n",
      "0.0018859815621909692\n",
      "-0.00148474530766457\n",
      "0.004201297453045955\n",
      "0.0008906106036383477\n",
      "-0.0017534587333397078\n",
      "0.00017466940681279408\n",
      "-0.0015905032433873867\n",
      "-0.0010550497447379403\n",
      "-0.001139493809149128\n",
      "-0.0009219238535224383\n",
      "0.0017405576880637763\n",
      "4.7644271322366816e-06\n",
      "-0.0009694855280096004\n",
      "-0.0010758830157812649\n",
      "-0.0006107430020682314\n",
      "0.0017355206914397292\n",
      "-0.0010542031961430498\n",
      "-0.0006326369429766332\n",
      "-0.0007778813046911137\n",
      "-0.001733051373505795\n",
      "-0.0016334729438211293\n",
      "0.0021602431607735673\n",
      "-0.00149597415561728\n",
      "-0.0010675736674567449\n",
      "-0.0017650449769082144\n",
      "-0.0007521936412600017\n",
      "0.0022634330578645\n",
      "-0.0017127436900389037\n",
      "-0.0010306765136194607\n",
      "0.001772423718878341\n",
      "0.002599196080771582\n",
      "0.002212621770082246\n",
      "0.0022058011136102673\n",
      "-0.0030707616368430835\n",
      "0.0022403093654862205\n",
      "0.0022606786765907716\n",
      "-0.0011975295360844296\n",
      "-0.0007234154699519435\n",
      "-0.0019226426686148324\n",
      "0.004039149880678883\n",
      "-0.00172635330637394\n",
      "-0.0010889937381365622\n",
      "0.002133664784445294\n",
      "-0.0007433917535939749\n",
      "0.001878708396389761\n",
      "0.0008461556838817719\n",
      "-0.0009440256151910797\n",
      "0.0019962906806053338\n",
      "0.0016723663602492\n",
      "-0.0011330661097816441\n",
      "1900 1% (0m 56s) 4.2821 by many native indian tribes have undoubtedly perished with the races to which they pertained but th / m ✗ (h)\n",
      "0.0008803795988500396\n",
      "0.0022443814389262184\n",
      "-0.0009259080983378687\n",
      "-0.0009465199021559956\n",
      "0.0022146992351156636\n",
      "0.002330684366711827\n",
      "-0.0009897013126246856\n",
      "0.001911131574775654\n",
      "-0.0018176968076769329\n",
      "-0.0012068170662667688\n",
      "0.002136735144726648\n",
      "-0.0007207864764278704\n",
      "-0.0010718212711923747\n",
      "-0.0010206696635932933\n",
      "-0.0006910496071940997\n",
      "0.0005921283400353028\n",
      "0.001906664737646141\n",
      "-0.0005328291162658982\n",
      "-0.001619999058494942\n",
      "0.0022218908757016542\n",
      "0.0020463471377493714\n",
      "0.002151859459291222\n",
      "-0.0015363032606147964\n",
      "0.002007656079109743\n",
      "0.0004886777664326047\n",
      "-0.0007908013779015788\n",
      "0.0014956768347945681\n",
      "0.0017851704592186657\n",
      "-0.0016472877413784281\n",
      "-0.0011623049863744017\n",
      "0.0019697886281424826\n",
      "0.0016350438553735247\n",
      "-0.00252485832001334\n",
      "-0.000802610211849103\n",
      "-0.0019230426645058252\n",
      "-0.0017486926373040945\n",
      "-0.0006463374980431591\n",
      "0.0015618959708552094\n",
      "4.318029768138332e-05\n",
      "-0.0016729017727599993\n",
      "0.0016245664323205622\n",
      "-0.0007559308750745841\n",
      "-0.0011131176509565632\n",
      "0.0020651214573469134\n",
      "0.0015795580515487184\n",
      "-0.001205199427768533\n",
      "-0.001625876393636344\n",
      "0.0018701093514274236\n",
      "0.00017883531416806875\n",
      "0.0019141017923733072\n",
      "1950 1% (0m 57s) 4.1941 he enthusiastic mystics by annexing the first stanza of the poem composed in the same year in which  / m ✗ ( )\n",
      "-0.001952240449936915\n",
      "-0.001262401031519117\n",
      "0.0019661343751496696\n",
      "0.0020023670494710155\n",
      "-0.0016611042440312918\n",
      "0.0018012912755611954\n",
      "0.0020369329561839844\n",
      "-0.0009076437890371825\n",
      "0.002030400918394626\n",
      "-3.944597022359497e-05\n",
      "-0.0026655424818612106\n",
      "8.998306849067328e-05\n",
      "-0.0011523675749795792\n",
      "0.0017956157400551565\n",
      "-0.002430172824344906\n",
      "0.0004070892016901084\n",
      "3.591721546400417e-05\n",
      "-0.001902575876438689\n",
      "-0.002153882711491528\n",
      "-0.0018273384002712445\n",
      "-0.0011962748113811261\n",
      "0.00022952075776427883\n",
      "-0.00249064786997108\n",
      "-0.000847486050624402\n",
      "-0.0008348262022102593\n",
      "0.0017291079197482295\n",
      "0.001851072936735726\n",
      "-0.0020255440852753603\n",
      "-0.001421961440838837\n",
      "-0.0014340735617094091\n",
      "-0.0016858964413359045\n",
      "0.0018042696287433324\n",
      "0.0019305215230578932\n",
      "0.0005614952785201188\n",
      "0.00201152105192004\n",
      "-0.0006840391421720493\n",
      "-0.003162755348057239\n",
      "0.0007219457681172936\n",
      "-0.0012828623274150353\n",
      "-0.0020605655583440796\n",
      "-0.0016301816198901753\n",
      "-0.002397468142456227\n",
      "-0.001184170214622221\n",
      "-0.0019659430844648773\n",
      "0.002104213624927437\n",
      "0.0005601558081046454\n",
      "0.002053909333777526\n",
      "0.00217623665887412\n",
      "0.00199522299765878\n",
      "0.0016065989436225558\n",
      "2000 2% (0m 59s) 4.2039 e had said she was not in pain as he listened to her regular breathing baird gradually lost his fear / m ✗ (r)\n",
      "0.002130240085322227\n",
      "0.0018274294444980688\n",
      "0.0015525934292096588\n",
      "-0.0016703839659044373\n",
      "0.0019304012051279962\n",
      "0.0024191752427156765\n",
      "0.0004444905558589618\n",
      "0.0007254701241274086\n",
      "-2.683125090677252e-05\n",
      "0.0018753738742359471\n",
      "0.003991172332259985\n",
      "8.101219940739868e-05\n",
      "-0.0021800326739741527\n",
      "0.0019684054933507833\n",
      "-0.0012458633019995224\n",
      "-0.001853721525320845\n",
      "0.0018992372149646275\n",
      "0.001402183175991889\n",
      "-0.001991916239256264\n",
      "0.002005592226707653\n",
      "0.0005139208583912758\n",
      "0.002019476095875272\n",
      "0.0021076311782404766\n",
      "0.001977551364164526\n",
      "-0.0014389972638628457\n",
      "0.001932160239852182\n",
      "0.0019044745956405817\n",
      "-0.001003544531084699\n",
      "-0.002069086274194276\n",
      "0.001793045447272934\n",
      "-0.00133138314258327\n",
      "-0.002565902020197769\n",
      "-0.0020400895149974285\n",
      "0.0015288823458203815\n",
      "0.0019602092317747566\n",
      "-0.0018057083216790892\n",
      "-0.0021291152427149185\n",
      "-0.0009306306071535098\n",
      "-0.0008483632390035301\n",
      "0.0004704405552820867\n",
      "-0.0017903737400971342\n",
      "-0.001512914532029036\n",
      "-0.0015878533947704387\n",
      "0.0014894263324820856\n",
      "0.0018442543284714896\n",
      "0.00184361324163676\n",
      "-0.0020665250527887036\n",
      "-0.0009058248452633866\n",
      "-0.0014204816305272705\n",
      "0.0020360222197103317\n",
      "2050 2% (1m 0s) 4.1893  for if its summat they ca help its fooilish to freeat an if its summat they can help why the deuce  / m ✗ ( )\n",
      "0.0019968228645559916\n",
      "0.0019325234348254727\n",
      "-0.0013093653071458988\n",
      "-0.0008995240779804958\n",
      "-0.0013466067082845423\n",
      "-8.017823174222283e-05\n",
      "0.0019892277908347133\n",
      "0.000513480163703034\n",
      "-1.5626413134739447e-05\n",
      "0.0014061026752781314\n",
      "7.452267025945258e-05\n",
      "0.0019786926859392817\n",
      "0.0017639244168480284\n",
      "-0.001350277137103728\n",
      "-9.399832203152436e-05\n",
      "-0.0014850999363505424\n",
      "0.0018925288892005787\n",
      "0.001301727700357136\n",
      "-0.0018493598713820447\n",
      "-0.001412057085237256\n",
      "0.0016993033746711406\n",
      "-0.0015567935454834925\n",
      "0.0017287485498712896\n",
      "0.0018222387441885757\n",
      "0.001749491700536926\n",
      "0.003725071803902885\n",
      "-0.0015002888417257887\n",
      "-0.001128136152708542\n",
      "-0.0011855958018723023\n",
      "0.0015682596405203475\n",
      "-0.0027122872582881763\n",
      "-0.0011808454702344762\n",
      "-0.0015055766708322316\n",
      "-0.0014492004457225538\n",
      "-0.002202255767300848\n",
      "-0.00218942435927727\n",
      "0.0016590156797594013\n",
      "-0.0015255534856195574\n",
      "0.0001863632545283933\n",
      "-0.0033628805670913586\n",
      "-0.0016114484886375624\n",
      "-0.0016718695367696768\n",
      "-0.002153380552284173\n",
      "0.001295536242068407\n",
      "-0.001088059427077681\n",
      "-0.001477570817070839\n",
      "0.001973235501920856\n",
      "0.0014910695988432643\n",
      "-0.002255254217493591\n",
      "-0.0018365114464471977\n",
      "2100 2% (1m 1s) 4.2926 to place this sallutio in the front of the battles as if he were the leader of the army for cæsar wa / m ✗ (a)\n",
      "-0.0009025409105204718\n",
      "-0.003353668036689267\n",
      "-0.0033546552927446738\n",
      "-0.0017092603619210944\n",
      "-0.0019800850790982205\n",
      "-0.0009765755200409898\n",
      "0.002106354143548872\n",
      "0.0019284954157477163\n",
      "0.0001881429730808959\n",
      "0.004032364571978669\n",
      "-0.0008091649556255798\n",
      "0.0017544176572430736\n",
      "5.775449275227662e-05\n",
      "-0.000809609037815795\n",
      "-0.0007490567476821086\n",
      "-0.000835662299857709\n",
      "0.0025134153224118105\n",
      "0.0020299742862443515\n",
      "0.0020084322043413816\n",
      "-0.0008436334545430246\n",
      "0.002020292532881579\n",
      "3.012260288745572e-05\n",
      "0.0019054404558822569\n",
      "0.0016769151488901235\n",
      "0.0017086593908855752\n",
      "0.002185029420483431\n",
      "0.0018775971916199785\n",
      "0.001983819699992617\n",
      "-0.0021450718678613923\n",
      "-0.0018202388404191805\n",
      "-0.0012492706885595672\n",
      "-0.0008452676300513273\n",
      "-0.002019518623401273\n",
      "0.000264894558636819\n",
      "-0.0008017512967863349\n",
      "0.0016547431592761896\n",
      "0.00016384672905733755\n",
      "0.0003957588912531784\n",
      "0.0019385816073958229\n",
      "0.0019261793549530393\n",
      "0.0014100519886420804\n",
      "0.0014425316808800437\n",
      "4.856517086981871e-06\n",
      "-0.0014657858333413931\n",
      "-0.0013624616549527402\n",
      "-0.0013582526516831006\n",
      "-0.0020771017871852315\n",
      "0.001924586696108982\n",
      "0.0002921065346923324\n",
      "0.0018246323402296982\n",
      "2150 2% (1m 3s) 4.1926  tt tt propugn hw tt tt v ety ets propugnare ets pro for ets pugnare to fight def to contend for to  / m ✗ ( )\n",
      "-1.2465545563000724e-06\n",
      "0.0004774517306130044\n",
      "0.0016466336003893023\n",
      "0.0018657525082088622\n",
      "0.002211145661807329\n",
      "-0.0019365216360515969\n",
      "-0.0014252887849958984\n",
      "4.501053607894323e-05\n",
      "-0.0014783167832841115\n",
      "0.0018935086112752686\n",
      "-0.00011213291745415521\n",
      "-0.0014081049270457946\n",
      "-0.002124235166586913\n",
      "0.001946578962382678\n",
      "-0.0015176910450573622\n",
      "-0.000918870227610169\n",
      "0.0018158884374238071\n",
      "0.0018737036319485256\n",
      "0.0016162879206555736\n",
      "0.00045631872867693546\n",
      "0.0014367986628337215\n",
      "-0.0013745587111165525\n",
      "0.0019434350689725988\n",
      "-0.0020848740892113193\n",
      "0.0019302737728341401\n",
      "0.0020030270019328056\n",
      "0.0015889534663966198\n",
      "0.0014119763919804018\n",
      "0.0019201742166047864\n",
      "-0.0013682255180142988\n",
      "-0.0008426870803446007\n",
      "-0.0014939373991110783\n",
      "-0.001121215705067985\n",
      "0.0004128202362857769\n",
      "-0.0013371147614451573\n",
      "0.0013388786796910968\n",
      "0.0016928994476869408\n",
      "0.00020720086484460332\n",
      "-0.0020730462433247165\n",
      "-0.000993799022707631\n",
      "-0.0020240003992091637\n",
      "-0.0015239440953509764\n",
      "-0.0011204599978070218\n",
      "-0.001442230921615606\n",
      "0.0004548021196920937\n",
      "-0.001061712182515051\n",
      "0.0018080836902980846\n",
      "-0.002096413488323512\n",
      "-0.00199092987630764\n",
      "-0.0034451642522675407\n",
      "2200 2% (1m 4s) 4.3378 dawn to the house of tom comstock editor of the and roused him out of bed i ll run it on the front p / m ✗ (p)\n",
      "0.0013506166026593935\n",
      "-0.0021688295314941097\n",
      "-0.0015745272399758925\n",
      "0.0018334406490920219\n",
      "0.0014299952002495286\n",
      "-0.0022948231875693503\n",
      "-0.0003030007470925522\n",
      "-0.0017200135337730182\n",
      "0.0015237076700937158\n",
      "-0.0010540604174812118\n",
      "0.001676418571565641\n",
      "0.0017943314717812076\n",
      "0.0016806487898536338\n",
      "0.0015422961755486575\n",
      "0.0017172732021442372\n",
      "-0.0011548651274877475\n",
      "0.0014674914682404616\n",
      "0.0011367623566728435\n",
      "-0.0017076350077459834\n",
      "0.0005369734170858342\n",
      "-4.679706592580768e-05\n",
      "0.0015012409966951856\n",
      "-0.002127702275831478\n",
      "0.0016694454127358926\n",
      "0.0013060592247143288\n",
      "-0.0010974747040218003\n",
      "0.0016943394638439524\n",
      "-0.0011977488996386954\n",
      "-0.0001664528491167605\n",
      "-0.001041527439668899\n",
      "0.0018046333362978229\n",
      "-0.0022047990351297952\n",
      "-0.0014723346477605592\n",
      "0.0017100602367697004\n",
      "-0.0011415203885955794\n",
      "0.0012879910906893055\n",
      "-0.0009320109314824299\n",
      "0.0005682265915924467\n",
      "-0.0015227684543060171\n",
      "-0.0014155770344333463\n",
      "-0.0034045221400020864\n",
      "-0.0014753478965046363\n",
      "-0.0009398846996827026\n",
      "-0.001842078427996885\n",
      "-3.998403741131695e-05\n",
      "-0.0009371260180769669\n",
      "0.0018963797723880182\n",
      "-0.0013481417065173418\n",
      "0.0014135113459110005\n",
      "-7.491800190301268e-05\n",
      "2250 2% (1m 6s) 4.2453  his intimate friends shaking hands with hardy entering a taxi leaving a taxi and paying the fare di / m ✗ (i)\n",
      "-0.0018869857476237761\n",
      "0.0019468423688030478\n",
      "0.0018803866570588634\n",
      "0.0004917658452062157\n",
      "-0.0020383236891038936\n",
      "-0.001319643802930287\n",
      "-0.0008240867447998068\n",
      "-0.001831333961953313\n",
      "-0.0018302708076569085\n",
      "-0.0017378074450683234\n",
      "0.0007060519044793379\n",
      "0.002000121661198756\n",
      "-0.00014334080712835595\n",
      "-0.0013145213226134211\n",
      "0.0020058876038960838\n",
      "0.001861904932919961\n",
      "0.003942978646025164\n",
      "0.001369886500845685\n",
      "0.001818366651940878\n",
      "-0.001883782067810591\n",
      "0.00013196117588806788\n",
      "0.0013947146911598707\n",
      "-0.0017269907199091161\n",
      "-0.0008940039450758552\n",
      "-0.0017723511652323887\n",
      "0.0019434226570004265\n",
      "0.000586313718424547\n",
      "-0.002037316309770998\n",
      "-0.0007930089242112193\n",
      "0.0021044036277781397\n",
      "0.0020371620726173656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iters \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     sequence, line_tensor \u001b[38;5;241m=\u001b[39m randomTrainingExample()\n\u001b[0;32m---> 25\u001b[0m     output, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Print ``iter`` number, loss, name and guess\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(line_tensor)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(line_tensor\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     10\u001b[0m     hot_input_char_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(line_tensor[i], num_classes\u001b[38;5;241m=\u001b[39mn_characters)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhot_input_char_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(\"output shape:\", output.shape)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(\"line_tensor shape:\", line_tensor.shape)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(output)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(line_tensor[-1].unsqueeze(0))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, line_tensor[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/memory_encoding/memory_encoding/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/memory_encoding/memory_encoding/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36mSimpleRNN.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Pass through the Hebbian linear layers with ReLU\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers:\n\u001b[0;32m---> 24\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     combined \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(combined)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Split into hidden and output\u001b[39;00m\n",
      "File \u001b[0;32m~/memory_encoding/memory_encoding/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/memory_encoding/memory_encoding/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mHebbianLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(input)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHebbianLinear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_imprints(\u001b[38;5;28minput\u001b[39m, output)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(output)\u001b[39;00m\n",
      "File \u001b[0;32m~/memory_encoding/memory_encoding/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 50\n",
    "plot_every = 10\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    sequence, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        # Use the output to generate a character prediction\n",
    "        topv, topi = output.topk(1, dim=1)  # Change dim to 1\n",
    "        predicted_char = text_dataset.idx_to_char[topi[0, 0].item()]\n",
    "        target_char = sequence[-1]\n",
    "        correct = '✓' if predicted_char == target_char else '✗ (%s)' % target_char\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, sequence, predicted_char, correct))\n",
    "\n",
    "        # also print some weights:\n",
    "        # print(\"i2h weights:\", rnn.i2h.weight)\n",
    "        # print(\"i2o weights:\", rnn.i2o.weight)\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
